{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3334ff70-add2-4d60-ab1a-d1bc3dd501d7",
   "metadata": {},
   "source": [
    "<a id=top-page></a>\n",
    "\n",
    "# Integrate `pykitPIV` with `LIMA`\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<font size=\"3\"><strong>Table of contents:</strong></font>\n",
    "<br>\n",
    "<ol>\n",
    "    <li><a href=\"#synthetic-images\">Generate synthetic images with pykitPIV</a></li>\n",
    "        <ul>\n",
    "        <li><a href=\"#synthetic-images-training-set\">Training set</a></li>\n",
    "        <li><a href=\"#synthetic-images-testing-set\">Testing set</a></li>\n",
    "        </ul>\n",
    "    <li><a href=\"#train-LIMA\">Train LIMA with the generated images</a></li>\n",
    "        <ul>\n",
    "        <li><a href=\"#train-LIMA-input-data\">Prepare input dataset for LIMA</a></li>\n",
    "        <li><a href=\"#train-LIMA-train\">Begin training</a></li>\n",
    "        </ul>\n",
    "    <li><a href=\"#predict\">Make predictions from the trained network</a></li>\n",
    "</ol>\n",
    "<p></p>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603d26ae-d712-41bf-9990-92c4248bf185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms\n",
    "from rich import print\n",
    "from torch.utils.data import DataLoader\n",
    "import lima\n",
    "import glob\n",
    "import h5py\n",
    "import skimage.io as io\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e938a73e-48fe-49d6-822c-6ec0807abadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cmcrameri.cm as cmc\n",
    "from pykitPIV import Particle, FlowField, Motion, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdedc10-9e08-447d-9e9f-55aea1ff9a31",
   "metadata": {},
   "source": [
    "<a id=synthetic-images></a>\n",
    "\n",
    "***\n",
    "\n",
    "## Generate synthetic images with `pykitPIV`\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa469657-bb96-40e8-b865-2616be55b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00898fb-0eeb-47f2-9d40-402739689623",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_buffer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f51f3-aa49-42c4-a40c-c76383a385fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e85233-0a70-421a-98a3-56ed768867a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(n_images, random_seed):\n",
    "\n",
    "    # Instantiate an object of the Particle class:\n",
    "    particles = Particle(n_images,\n",
    "                         size=image_size,\n",
    "                         size_buffer=size_buffer,\n",
    "                         diameters=(4,4.1),\n",
    "                         distances=(1,2),\n",
    "                         densities=(0.05,0.1),\n",
    "                         signal_to_noise=(5,20),\n",
    "                         diameter_std=0.2,\n",
    "                         seeding_mode='random',\n",
    "                         random_seed=random_seed)\n",
    "\n",
    "    # Instantiate an object of the FlowField class:\n",
    "    flowfield = FlowField(n_images,\n",
    "                          size=image_size,\n",
    "                          size_buffer=size_buffer,\n",
    "                          flow_mode='random',\n",
    "                          gaussian_filters=(10,11),\n",
    "                          n_gaussian_filter_iter=20,\n",
    "                          sin_period=(30,300),\n",
    "                          displacement=(0,10),\n",
    "                          random_seed=random_seed)\n",
    "\n",
    "    # Instantiate an object of the Motion class:\n",
    "    motion = Motion(particles, \n",
    "                    flowfield, \n",
    "                    time_separation=0.1)\n",
    "\n",
    "    # Instantiate an object of the Image class:\n",
    "    image = Image(random_seed=random_seed)\n",
    "\n",
    "    # Prepare images - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "    image.add_particles(particles)\n",
    "\n",
    "    image.add_velocity_field(flowfield)\n",
    "            \n",
    "    motion.forward_euler(n_steps=10)\n",
    "    \n",
    "    image.add_motion(motion)\n",
    "    \n",
    "    image.add_reflected_light(exposures=(0.7,0.8),\n",
    "                              maximum_intensity=2**16-1,\n",
    "                              laser_beam_thickness=1,\n",
    "                              laser_over_exposure=1,\n",
    "                              laser_beam_shape=0.95,\n",
    "                              alpha=1/10)\n",
    "\n",
    "    image.remove_buffers()\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc64d21f-c1fe-4750-ac1c-f35d67a432c2",
   "metadata": {},
   "source": [
    "<a id=synthetic-images-training-set></a>\n",
    "\n",
    "### Training set\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f553e40-be62-4459-a698-26aede7872dd",
   "metadata": {},
   "source": [
    "The training set will have 10 image pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa253c-0507-48b3-928b-46f2a5c0e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c395e4f9-1653-4bc8-936d-147190b2dc62",
   "metadata": {},
   "source": [
    "We fix a random seed for generating the training set of PIV images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f99854-fe8b-4851-8f3a-7f8d7c6b09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_random_seed = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476aa953-6f12-40cc-ae46-042d84103067",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = generate_images(n_images, training_random_seed)\n",
    "\n",
    "image_pairs_train = image_train.image_pairs_to_tensor()\n",
    "targets_train = image_train.targets_to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8cb11-d2a7-4083-abb0-a8629b180052",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train.plot(0,\n",
    "                 instance=1,\n",
    "                 with_buffer=True,\n",
    "                 xlabel='Width [px]',\n",
    "                 ylabel='Height [px]',\n",
    "                 cmap='Greys_r',\n",
    "                 figsize=figsize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dfb1be-a049-4eae-a31b-a41f8ee161e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train.plot_velocity_field(2, \n",
    "                                cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b7a28-04ed-45a7-9085-082f14d94cd6",
   "metadata": {},
   "source": [
    "<a id=synthetic-images-testing-set></a>\n",
    "\n",
    "### Testing set\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b2187c-883c-43c5-9f5f-dde87b0cb5da",
   "metadata": {},
   "source": [
    "The test set will have 10 image pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f510c1b-b8c1-49a4-8e61-67bb13e48fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b13bea-0661-4726-97da-b2251546647e",
   "metadata": {},
   "source": [
    "We fix a random seed for generating the test set of PIV images (which is different from the random seed for the training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668f73b-c0c5-42c5-899a-82e72b8098cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_random_seed = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba806bc8-82cd-4211-8a7e-cc4486753d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = generate_images(n_images, test_random_seed)\n",
    "\n",
    "image_pairs_test = image_test.image_pairs_to_tensor()\n",
    "targets_test = image_test.targets_to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1a1d6-7745-4551-85f8-c4eea982cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test.plot(0,\n",
    "                instance=1,\n",
    "                with_buffer=True,\n",
    "                xlabel='Width [px]',\n",
    "                ylabel='Height [px]',\n",
    "                cmap='Greys_r',\n",
    "                figsize=figsize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1369f8cf-dae1-41b6-9149-8453afd0c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test.plot_velocity_field(0,\n",
    "                               cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9529ac-04f7-45a7-b392-8bc7b6379c8a",
   "metadata": {},
   "source": [
    "<a id=train-LIMA></a>\n",
    "***\n",
    "\n",
    "## Train `LIMA` with the generated images\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7e34e-b9d5-4801-bdb1-8edd07ccd4c3",
   "metadata": {},
   "source": [
    "<a id=train-LIMA-input-data></a>\n",
    "### Prepare input dataset for LIMA\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b01577-ff6f-4dc7-8fde-fc9f02cbea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([lima.transforms.RandomAffine(degrees=17, translate=(0.2, 0.2), scale=(0.9, 2.0)),\n",
    "                                            lima.transforms.RandomHorizontalFlip(),\n",
    "                                            lima.transforms.RandomVerticalFlip(),\n",
    "                                            lima.transforms.ToTensor(),\n",
    "                                            lima.transforms.RandomBrightness(factor=(0.5, 2)),\n",
    "                                            lima.transforms.RandomNoise(std=(0, 0)),])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb78a4-858c-4864-b76f-18dd4af76a89",
   "metadata": {},
   "source": [
    "#### Use dataset generated with `pykitPIV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e705b1-cc07-44e1-8ea0-27e9d4d046db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pykitPIVDataset(Dataset):\n",
    "    \"\"\"Load pykitPIV-generated dataset\"\"\"\n",
    "\n",
    "    def __init__(self, image_pairs, targets, transform=None, n_samples=None, pin_to_ram=False):\n",
    "\n",
    "        self.data = image_pairs\n",
    "        self.target = targets\n",
    "\n",
    "        if n_samples:\n",
    "            self.data = self.data[:n_samples]\n",
    "            self.target = self.target[:n_samples]\n",
    "        if pin_to_ram:\n",
    "            self.data = np.array(self.data)\n",
    "            self.target = np.array(self.target)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = self.data[idx], self.target[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e9992-d893-465a-9771-5d7731d75c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pykitPIVDataset(image_pairs=image_pairs_train,\n",
    "                                targets=targets_train,\n",
    "                                transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f81ad-1d42-441d-96e1-15eb95471a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pykitPIVDataset(image_pairs=image_pairs_test,\n",
    "                                targets=targets_test,\n",
    "                                transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c38dcc-9ca2-4e76-b7b3-031e9bfb180d",
   "metadata": {},
   "source": [
    "#### Use dataset generated with Matlab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5074828-00b9-455c-bced-0efbb430f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'PIV_n3_s180_maxd10_rnd_v1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc9631-f90f-4ff5-b82f-8305e7be51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = h5py.File(path, \"r\")\n",
    "\n",
    "# images = f[\"I\"]\n",
    "# images = np.array(images)\n",
    "# targets = f[\"target\"]\n",
    "# targets = np.array(targets)[:,2:4,:,:]\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce131801-974f-404e-a402-52aebd83a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.array(images)[0,0,:,:], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68a329-5720-49b1-8a89-e1f7793e0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Dataset(Dataset):\n",
    "    \"\"\"HDF5Dataset loaded\"\"\"\n",
    "\n",
    "    def __init__(self, path, transform=None, n_samples=None, pin_to_ram=False):\n",
    "        f = h5py.File(path, \"r\")\n",
    "        self.data = f[\"I\"]\n",
    "        self.target = np.array(f[\"target\"])[:,2:4,:,:]\n",
    "\n",
    "        if n_samples:\n",
    "            self.data = self.data[:n_samples]\n",
    "            self.target = self.target[:n_samples]\n",
    "        if pin_to_ram:\n",
    "            self.data = np.array(self.data)\n",
    "            self.target = np.array(self.target)\n",
    "            f.close()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = self.data[idx], self.target[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd2f0d-3ebc-4cd9-ae9a-276a418056d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HDF5Dataset(path=path,\n",
    "                            transform=transform,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35612cb1-32d0-4fbe-a59b-e292b8ad365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = HDF5Dataset(path=path,\n",
    "                           transform=transform,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b64556-51d8-44b3-8de8-d8ee1d0e93c5",
   "metadata": {},
   "source": [
    "<a id=train-LIMA-train></a>\n",
    "### Begin training\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26a0fb-5c98-4b92-b28d-8fbc52b7e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=5,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1,\n",
    "                          pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c02df-f0b8-4468-a52b-eb64f8c9cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c371af-27e4-46ff-8c54-20658c8ba1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(random_seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a7dce-568d-4476-bd0a-1a66a1586860",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train_loader = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cfa054-af86-4245-96f6-8064a80dc84a",
   "metadata": {},
   "source": [
    "Define the LIMA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5d40f-d5c9-42bd-8b4c-1feb5f4a1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_flow = 0.05\n",
    "loss_weights = [0.32, 0.08, 0.02, 0.01, 0.005, 0.0025, 0.00125]\n",
    "search_range = 4\n",
    "num_chs = [1, 16, 32, 64, 96, 128, 196]\n",
    "num_chs = [1, 16, 32]\n",
    "output_level = 4\n",
    "loss = 'l1_loss'\n",
    "loss_weights_order = 'inc'\n",
    "loss_J = 'abs'\n",
    "loss_J_gamma = 1e-1\n",
    "full_res = False\n",
    "full_res_loss_weight_multiplier = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313fe7e-3496-4630-b61e-9a6508f525c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lima.LIMA(div_flow=div_flow,\n",
    "                  loss_weights=loss_weights,\n",
    "                  search_range=search_range,\n",
    "                  num_chs=num_chs,\n",
    "                  output_level=output_level,\n",
    "                  loss=loss,\n",
    "                  loss_weights_order=loss_weights_order,\n",
    "                  loss_J=loss_J,\n",
    "                  loss_J_gamma=loss_J_gamma,\n",
    "                  full_res=full_res,\n",
    "                  full_res_loss_weight_multiplier=full_res_loss_weight_multiplier,\n",
    "                  epochs=10,\n",
    "                  optimizer='Adam',\n",
    "                  base_lr=0.001,\n",
    "                  weight_decay=4e-4,\n",
    "                  momentum=0.9,\n",
    "                  num_workers=20,\n",
    "                  beta=0.999,\n",
    "                  reduction=\"sum\",\n",
    "                  scheduler='ReduceLROnPlateau',\n",
    "                  lr_decay=0.2,\n",
    "                  patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85c26e-e5af-423c-bf74-ef51f540c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27093e8b-3395-4e01-adc5-0857d7f0830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model,\n",
    "            train_loader,\n",
    "            test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c376df4-1cf6-4a4a-a449-97616f514056",
   "metadata": {},
   "source": [
    "<a id=predict></a>\n",
    "***\n",
    "\n",
    "## Make predictions from the trained network\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf0a00f-d8af-490f-ba71-f2ef67952347",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_predict = 0\n",
    "velocity_component = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17187496-c4bc-485d-bfd5-1134ff8c83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(image_pairs_test[image_to_predict,:,:,:]).to(dtype=torch.float).type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035b544-cf36-4cb4-ae3b-672ac7395a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_flow = model.inference(torch.from_numpy(image_pairs_test[image_to_predict,:,:,:]).to(dtype=torch.float)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d5457-9802-4155-a92a-68376091fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted_flow[velocity_component,:,:], \n",
    "           cmap='Blues', \n",
    "           origin='lower')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf324ff8-419c-4ef6-a0f5-6319e8ad80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(targets_test[image_to_predict,velocity_component,:,:], \n",
    "           cmap='Blues', \n",
    "           origin='lower')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb3fb9-edee-4317-804a-a81600b35a0e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9d92d-861e-46ee-8368-36d4fbd440a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919b20a-8d0f-48c5-86d0-77c9fc4a701b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae0a84-26cb-4cff-90ee-13a3b6b9b7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "427e588a-51a3-4984-a67c-33a42bbff6b3",
   "metadata": {},
   "source": [
    "```\n",
    "    'batch_size': 4,\n",
    "    'base_lr': 0.0001,\n",
    "    'lr_gamma': 0.5,\n",
    "    'weight_decay': 0.0004,\n",
    "    'momentum': 0.9,\n",
    "    'beta': 0.999,\n",
    "    'milestones': [60, 80, 100, 120, 140],\n",
    "    'warmup_epochs': 5,\n",
    "    'optimizer': 'Adam',\n",
    "    'scheduler': 'ReduceLROnPlateau',\n",
    "    'epochs': 20,\n",
    "    'lr_decay': 0.2,\n",
    "    'patience': 10,\n",
    "    'noise_std': 0,\n",
    "    'output_level': 6,\n",
    "    'loss': 'l1_loss',\n",
    "    'reduction': 'sum',\n",
    "    'loss_weights_order': 'inc',\n",
    "    'loss_J': 'abs',\n",
    "    'loss_J_gamma': 0.1,\n",
    "    'full_res': False,\n",
    "    'full_res_loss_weight_multiplier': 4.0,\n",
    "    'project': 'test',\n",
    "    'run': None,\n",
    "    'log_interval': 5,\n",
    "    'comment': '',\n",
    "    'seed': 5738,\n",
    "    'num_workers': 4,\n",
    "    'dataset': 'rand_L_lag',\n",
    "    'logger': True,\n",
    "    'checkpoint_callback': None,\n",
    "    'enable_checkpointing': True,\n",
    "    'default_root_dir': None,\n",
    "    'gradient_clip_val': None,\n",
    "    'gradient_clip_algorithm': None,\n",
    "    'process_position': 0,\n",
    "    'num_nodes': 1,\n",
    "    'num_processes': 1,\n",
    "    'devices': None,\n",
    "    'gpus': None,\n",
    "    'auto_select_gpus': False,\n",
    "    'tpu_cores': None,\n",
    "    'ipus': None,\n",
    "    'log_gpu_memory': None,\n",
    "    'progress_bar_refresh_rate': None,\n",
    "    'enable_progress_bar': True,\n",
    "    'overfit_batches': 0.0,\n",
    "    'track_grad_norm': -1,\n",
    "    'check_val_every_n_epoch': 1,\n",
    "    'fast_dev_run': False,\n",
    "    'accumulate_grad_batches': None,\n",
    "    'max_epochs': None,\n",
    "    'min_epochs': None,\n",
    "    'max_steps': -1,\n",
    "    'min_steps': None,\n",
    "    'max_time': None,\n",
    "    'limit_train_batches': 1.0,\n",
    "    'limit_val_batches': 1.0,\n",
    "    'limit_test_batches': 1.0,\n",
    "    'limit_predict_batches': 1.0,\n",
    "    'val_check_interval': 1.0,\n",
    "    'flush_logs_every_n_steps': None,\n",
    "    'log_every_n_steps': 50,\n",
    "    'accelerator': None,\n",
    "    'strategy': None,\n",
    "    'sync_batchnorm': False,\n",
    "    'precision': 32,\n",
    "    'enable_model_summary': True,\n",
    "    'weights_summary': 'top',\n",
    "    'weights_save_path': None,\n",
    "    'num_sanity_val_steps': 2,\n",
    "    'resume_from_checkpoint': None,\n",
    "    'profiler': None,\n",
    "    'benchmark': False,\n",
    "    'deterministic': False,\n",
    "    'reload_dataloaders_every_n_epochs': 0,\n",
    "    'reload_dataloaders_every_epoch': False,\n",
    "    'auto_lr_find': False,\n",
    "    'replace_sampler_ddp': True,\n",
    "    'detect_anomaly': False,\n",
    "    'auto_scale_batch_size': False,\n",
    "    'prepare_data_per_node': None,\n",
    "    'plugins': None,\n",
    "    'amp_backend': 'native',\n",
    "    'amp_level': None,\n",
    "    'move_metrics_to_cpu': False,\n",
    "    'multiple_trainloader_mode': 'max_size_cycle',\n",
    "    'stochastic_weight_avg': False,\n",
    "    'terminate_on_nan': None\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f383c-a27f-4648-a6b2-7f965aae2c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
