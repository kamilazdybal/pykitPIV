{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28fed105-acc8-4b6f-962e-95c044f24d47",
   "metadata": {},
   "source": [
    "<a id=top-page></a>\n",
    "# `pykitPIV` demo: Learn to locate sources/sinks in a 2D PIV experiment using reinforcement learning\n",
    "\n",
    "## Double deep Q-network with memory replay\n",
    "\n",
    "In this Jupyter notebook, we show how the available functionalities from the machine learning module (`pykitPIV.ml`) can be used to train a reinforcement learning (RL) agent to navigate the virtual PIV camera towards sources/sinks in a radial flow.\n",
    "\n",
    "The agent can perform one of five actions:\n",
    "\n",
    "- Move up\n",
    "- Move down\n",
    "- Move right\n",
    "- Move left\n",
    "- Stay\n",
    "\n",
    "on the virtual camera, thereby with each step moving the virtual PIV camera by $N$ pixels.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<font size=\"3\"><strong>Table of contents:</strong></font>\n",
    "<br>\n",
    "<ol>\n",
    "    <li><a href=\"#initializations\">Initializations</a></li>\n",
    "    <li><a href=\"#generate-velocity-field\">Generate random velocity field to advect the particles</a></li>\n",
    "    <li><a href=\"#add-movement\">Add movement to particles</a></li>\n",
    "        <ul>\n",
    "        <li><a href=\"#add-movement-update-time-sep\">Update time separation</a></li>\n",
    "        <li><a href=\"#add-movement-visualize\">Visualize the PIV image pair</a></li>\n",
    "        </ul>\n",
    "    <li><a href=\"#save\">Save the dataset</a></li>\n",
    "    <li><a href=\"#upload\">Upload the saved datasets</a></li>\n",
    "</ol>\n",
    "<p></p>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442604c-be37-4b9a-8c1c-0c08c717d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykitPIV.ml import PIVEnv, CameraAgentDoubleDQN, Rewards, Cues, plot_trajectory\n",
    "from pykitPIV.flowfield import compute_q_criterion, compute_divergence\n",
    "from pykitPIV import ParticleSpecs, FlowFieldSpecs, MotionSpecs, ImageSpecs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import cmcrameri.cm as cmc\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import sys, os\n",
    "import time\n",
    "import copy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700d1e6-808a-4fc9-8790-bfcbcca6d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images = False\n",
    "filename = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5940d-c27b-49e9-a974-b69c3ab990a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_colors = cmc.batlow(np.linspace(0, 1, 5))\n",
    "cmap_actions = ListedColormap(action_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc6559-5d5a-45f7-984c-245eb6f73a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrogation_window_size = (100,100)\n",
    "interrogation_window_size_buffer = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06129ede-9b88-4793-a8a1-95065bddc272",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5541e-15bd-420c-9cce-55d4ffabf8c6",
   "metadata": {},
   "source": [
    "### Prepare specifications for pykitPIV parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0797d34e-fec2-4aae-9376-d9a2d09bfa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_spec = ParticleSpecs(diameters=(1, 1),\n",
    "                              distances=(2, 2),\n",
    "                              densities=(0.4, 0.4),\n",
    "                              diameter_std=0,\n",
    "                              seeding_mode='random')\n",
    "\n",
    "print(particle_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c5effc-8435-4342-a0d6-bd32d448b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowfield_spec = FlowFieldSpecs(size=(200,500),\n",
    "                                flowfield_type='radial',\n",
    "                                radial_epsilon=1e-6,\n",
    "                                radial_source=True,\n",
    "                                radial_sigma=20,\n",
    "                                radial_imposed_source_location=None,\n",
    "                                displacement=(2, 2))\n",
    "\n",
    "print(flowfield_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11035f5-11be-4ae2-84bd-8d1c380b110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_spec = MotionSpecs(n_steps=10,\n",
    "                          time_separation=1,\n",
    "                          particle_loss=(0, 0),\n",
    "                          particle_gain=(0, 0))\n",
    "\n",
    "print(motion_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9559313-6085-4dd9-b912-db94ca05407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_spec = ImageSpecs(exposures=(0.98, 0.98),\n",
    "                        maximum_intensity=2**16-1,\n",
    "                        laser_beam_thickness=1,\n",
    "                        laser_over_exposure=1,\n",
    "                        laser_beam_shape=0.95,\n",
    "                        alpha=1/8,\n",
    "                        clip_intensities=True,\n",
    "                        normalize_intensities=False)\n",
    "\n",
    "print(image_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d1764-2e92-4ae1-807c-4971131005b4",
   "metadata": {},
   "source": [
    "### Prepare the CNN-based inference model for PIV images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fc888-c3da-49fd-87b2-ca0f4990848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ONNXmodel:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 onnx_file_path):\n",
    "        \n",
    "        self.name = \"ONNX\"\n",
    "        self.providers = ['CPUExecutionProvider']\n",
    "        self.session = onnxruntime.InferenceSession(onnx_file_path, \n",
    "                                                    None,\n",
    "                                                    providers=self.providers)\n",
    "\n",
    "        self.input_name = self.session.get_inputs()[0].name  \n",
    "        print('Input Name:', self.input_name)   \n",
    " \n",
    "    def inference(self, x):\n",
    "        \n",
    "        output = self.session.run([], {self.input_name:x/np.max(x)})[0] \n",
    "      \n",
    "        return output\n",
    "\n",
    "    def empty(self):\n",
    "        \n",
    "         with torch.no_grad():\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1814c-d029-4ad0-95f0-6382f6213ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = '../Lima_L4_PAD_SR2_dyn.onnx'\n",
    "print(\"model:\", model_file, '  exist:', os.path.exists(model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814774a-3919-498d-b2fd-0217b634d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "lima_inference_model = ONNXmodel(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b2b6b-1c9c-4d00-ab01-6fc7c9d9776d",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Create the RL environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce70f4-bde4-4e38-814e-e31db23c08d2",
   "metadata": {},
   "source": [
    "Define the cues that the RL agent effectively senses and learns from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e534d67-2751-40bd-8a48-cae84aad63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cues_obj = Cues(sample_every_n=10, \n",
    "                normalize_displacement_vectors=False)\n",
    "\n",
    "cues_function = cues_obj.sampled_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca8abad-37f7-41c3-ab8b-22f1073b5f0b",
   "metadata": {},
   "source": [
    "Initialize the `Gymnasium`-based virtual wind tunnel environment using the `PIVEnv` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30205c9-39af-47d6-a5d8-c94ac070abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PIVEnv(interrogation_window_size=interrogation_window_size,\n",
    "             interrogation_window_size_buffer=interrogation_window_size_buffer,\n",
    "             cues_function=cues_function,\n",
    "             particle_spec=particle_spec,\n",
    "             motion_spec=motion_spec,\n",
    "             image_spec=image_spec,\n",
    "             flowfield_spec=flowfield_spec,\n",
    "             inference_model=None,\n",
    "             random_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f8ce9-1c00-4f61-b681-3bd169e8a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_position, cues = env.reset(imposed_camera_position=np.array([40, 20]), regenerate_flowfield=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2011cce6-f637-4797-a806-ffbd35060f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc42726-8e29-46a0-a8af-c9f0f70c1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = env.render(quantity=None,\n",
    "                 camera_position=camera_position,\n",
    "                 c='white',\n",
    "                 s=20,\n",
    "                 lw=1,\n",
    "                 normalize_cbars=True,\n",
    "                 cmap=cmc.roma,\n",
    "                 add_streamplot=True,\n",
    "                 streamplot_density=1,\n",
    "                 streamplot_color='k',\n",
    "                 streamplot_linewidth=0.5,\n",
    "                 figsize=(13,5), \n",
    "                 filename='ml_PIVEnv_render.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7569c7-d9f5-4a6a-be8f-e2178e3fe7c3",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Create and train the RL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd242df-d133-40e5-8f0c-e4a2b8a489d6",
   "metadata": {},
   "source": [
    "We will train the RL agent on 1000 episodes, where at the beginning of each new episose, a new radial field is generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa4346-3dfb-4bc5-92db-a83eb1ebb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a65ea7-2451-4240-a08e-0827747cff8e",
   "metadata": {},
   "source": [
    "We will let the RL agent take 20 steps (camera movements) per episode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83105287-2268-408f-aeb9-68956f3aa562",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefef644-fd2c-47c2-9271-9797fad95faa",
   "metadata": {},
   "source": [
    "Each step will be magnified 10 times, i.e., instead of the step being a movement of camera by 1px, it will be a movement by 10px:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fed917-7567-49a9-8e32-3f4a29b6bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnify_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a1599-cb13-4fc0-85f6-740121c9a3b2",
   "metadata": {},
   "source": [
    "Define the discount factor for the future rewards, $\\gamma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169521a-14da-4e24-b09b-44c48240d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factor = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d7b78-0533-4b51-a355-a43b0e36c2a2",
   "metadata": {},
   "source": [
    "Specify the parameters for the $\\varepsilon$-greedy policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b1692-5f9d-4c1f-8575-8a60c2bc9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_start = 0.5\n",
    "epsilon_end = 0.0\n",
    "n_episodes_epsilon_decay = 4800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee179bb-c254-42fc-8038-18e520782e25",
   "metadata": {},
   "source": [
    "Specify the parameters for the learning rate decay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a846a57-722f-4602-bedd-13e2679a49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "alpha_lr = 0.01\n",
    "n_episodes_learning_rate_decay = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc5827-38e0-4bdc-b2de-3b5a23deb626",
   "metadata": {},
   "source": [
    "Specify the batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1e957-053e-4384-bc97-c1061f9324c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd8eeb6-d25d-42f8-85a5-1ff56a20dca3",
   "metadata": {},
   "source": [
    "Specify the memory size for memory replay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21614365-9b2d-4134-a2fa-9c4110e93854",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bb89ec-729a-4c2e-9fa5-5f51954ee133",
   "metadata": {},
   "source": [
    "Specify the number of epochs for training on each step in the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4d08d-614e-410e-906f-f763f1fba917",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768b95e1-d977-4eac-b275-7e652b53bc7f",
   "metadata": {},
   "source": [
    "Specify the kernel initializer for the weights in the Q-network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9a77f-dd2b-4a1b-8d3a-86a6392ad1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_initializer = tf.keras.initializers.RandomUniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf67aa3c-143d-4ecd-a534-3a4549024793",
   "metadata": {},
   "source": [
    "Specify the gradient descent optimizer to use, it can be `'RMSprop'` or `'Adam'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d193bf-f773-44a8-aa45-16912aa752ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'Adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d0870-32fe-4761-99b8-8ba22c592cc6",
   "metadata": {},
   "source": [
    "Define the exploration probability decay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c072a-edc0-45d3-86f2-b4c9c5c75f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_decay(episode, \n",
    "                  epsilon_start,\n",
    "                  epsilon_end,\n",
    "                  n):\n",
    "    \n",
    "    if episode < n:\n",
    "        return epsilon_start - (episode / n) * (epsilon_start - epsilon_end)\n",
    "    else:\n",
    "        return epsilon_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950cfb22-7bbf-4e62-ba83-bdec061932cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_probabilities = []\n",
    "\n",
    "for i in range(0,n_episodes):\n",
    "\n",
    "    exploration_probabilities.append(epsilon_decay(i, epsilon_start, epsilon_end, n=n_episodes_epsilon_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecfe9a3-ac06-4913-b307-75dd8dc0acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,2))\n",
    "plt.plot(exploration_probabilities, c='k', lw=3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel(r'Exploration probability, $\\varepsilon$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df3c986-3280-4bed-b6d7-bc75313b5dd9",
   "metadata": {},
   "source": [
    "Define the cosine learning rate decay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4d90c-6972-4069-ba08-a610eac780a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_decay(episode, \n",
    "                        initial_learning_rate, \n",
    "                        alpha_lr, \n",
    "                        n):\n",
    "    \n",
    "    episode = np.min([episode, n])\n",
    "    cosine_decay = 0.5 * (1 + np.cos(np.pi * episode / n))\n",
    "    decayed = (1 - alpha_lr) * cosine_decay + alpha_lr\n",
    "    \n",
    "    return initial_learning_rate * decayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f3bed-1fc3-4d09-b398-565d9d041162",
   "metadata": {},
   "outputs": [],
   "source": [
    "decayed_learning_rates = []\n",
    "\n",
    "for i in range(0,n_episodes):\n",
    "\n",
    "    decayed_learning_rates.append(learning_rate_decay(i,\n",
    "                                                      initial_learning_rate=initial_learning_rate, \n",
    "                                                      alpha_lr=alpha_lr, \n",
    "                                                      n=n_episodes_learning_rate_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8123a34-ab49-4477-8b5d-c1d776f6f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,2))\n",
    "plt.semilogy(decayed_learning_rates, c='k', lw=3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel(r'Learning rate, $\\alpha$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f5d2d-8081-4c83-a864-64af17ea1dff",
   "metadata": {},
   "source": [
    "We define the architecture for the deep Q-network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6cc52d-d21d-47b4-b05a-bb7e25f99df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_hidden_unit = int(env.n_cues/2)\n",
    "size_of_hidden_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140daefe-d0d6-47f3-8017-6338936024bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, n_actions, kernel_initializer):\n",
    "\n",
    "        super(QNetwork, self).__init__()\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(env.n_cues, activation='relu', kernel_initializer=kernel_initializer)\n",
    "        self.dense2 = tf.keras.layers.Dense(size_of_hidden_unit, activation='relu', kernel_initializer=kernel_initializer)\n",
    "        self.dense3 = tf.keras.layers.Dense(size_of_hidden_unit, activation='relu', kernel_initializer=kernel_initializer)\n",
    "        self.output_layer = tf.keras.layers.Dense(n_actions, activation='relu', kernel_initializer=kernel_initializer)\n",
    "\n",
    "    def call(self, state):\n",
    "\n",
    "        x = self.dense1(state)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d94bad-03e4-4682-8347-9bb7c18ea645",
   "metadata": {},
   "source": [
    "Initialize the camera agent using the `CameraAgent` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba5022-490d-43da-adb4-df5f762b841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = CameraAgent(env=env,\n",
    "                 target_q_network=QNetwork(env.n_actions, kernel_initializer),\n",
    "                 online_q_network=QNetwork(env.n_actions, kernel_initializer),\n",
    "                 memory_size=memory_size,\n",
    "                 batch_size=batch_size,\n",
    "                 n_epochs=n_epochs,\n",
    "                 learning_rate=initial_learning_rate,\n",
    "                 optimizer='Adam',\n",
    "                 discount_factor=discount_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d2258-fa31-466c-a123-312886f30d1b",
   "metadata": {},
   "source": [
    "We are going to use the reward based on divergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82d9ac-d6f4-4aed-a531-725652bfdc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = Rewards(verbose=False)\n",
    "reward_function = rewards.divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabc8ad-9094-4cce-b7ec-fe2e4567d721",
   "metadata": {},
   "source": [
    "Define a transformation function for the reward which is appropriate to detecting regions of high divergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b3bcd-b625-49b0-8571-f0ed93a96b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_transformation(div):  \n",
    "    return np.max(np.abs(div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6ee3d-0b25-46ab-8e6e-0941297c2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tic = time.perf_counter()\n",
    "\n",
    "print()\n",
    "print('- '*50)\n",
    "print('Starting training the RL agent...\\n')\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "iter_count = 0\n",
    "total_rewards = []\n",
    "current_lr = cp.deepcopy(initial_learning_rate)\n",
    "\n",
    "batch_q_values_collected = np.zeros((1, env.n_actions))\n",
    "\n",
    "log_every = 1\n",
    "\n",
    "for episode in range(0, n_episodes):\n",
    "\n",
    "    camera_position, cues = ca.env.reset(regenerate_flowfield=True)\n",
    "    total_reward = 0\n",
    "\n",
    "    # Before we start training the Q-network, only exploration is allowed:\n",
    "    if len(ca.memory.buffer) >= batch_size:\n",
    "\n",
    "        # Exploration probability decreases with training time:\n",
    "        epsilon = epsilon_decay(episode=iter_count, \n",
    "                                epsilon_start=epsilon_start,\n",
    "                                epsilon_end=epsilon_end,\n",
    "                                n=n_episodes_epsilon_decay)\n",
    "\n",
    "        # Decay the learning rate:\n",
    "        current_lr = learning_rate_decay(episode=iter_count, \n",
    "                                         initial_learning_rate=initial_learning_rate, \n",
    "                                         alpha_lr=alpha_lr, \n",
    "                                         n=n_episodes_learning_rate_decay)\n",
    "        \n",
    "        iter_count += 1  # Only counts episodes that had Q-network trainings in them\n",
    "\n",
    "    else:\n",
    "\n",
    "        epsilon = 1.0\n",
    "\n",
    "    if (episode) % log_every == 0:\n",
    "\n",
    "        print(f'Episode: {episode + 1}')\n",
    "        print(f'Epsilon: {epsilon:0.3f}')\n",
    "        print('Learning rate: ' + str(current_lr))\n",
    "\n",
    "    for i in range(0,n_iterations):\n",
    "\n",
    "        action = ca.choose_action(cues,\n",
    "                                  epsilon=epsilon)\n",
    "\n",
    "        next_camera_position, next_cues, reward = ca.env.step(action,\n",
    "                                                              reward_function=reward_function,\n",
    "                                                              reward_transformation=reward_transformation,\n",
    "                                                              magnify_step=magnify_step,\n",
    "                                                              verbose=False)\n",
    "\n",
    "        ca.remember(cues,\n",
    "                    action,\n",
    "                    reward,\n",
    "                    next_cues)\n",
    "\n",
    "        cues = next_cues\n",
    "        total_reward += reward\n",
    "\n",
    "        # Train the Q-network after each step, (but hold off with training until batch_size of samples is collected):\n",
    "        if len(ca.memory.buffer) >= batch_size:\n",
    "\n",
    "            ca.train(current_lr)\n",
    "\n",
    "    batch_q_values = ca.online_q_network(cues).numpy()\n",
    "    batch_q_values_collected = np.vstack((batch_q_values_collected, batch_q_values))\n",
    "\n",
    "    # Synchronize the Q-networks only at the end of each episode:\n",
    "    if len(ca.memory.buffer) >= batch_size:\n",
    "        ca.update_target_network()\n",
    "    \n",
    "    if (episode) % log_every == 0:\n",
    "\n",
    "        toc = time.perf_counter()\n",
    "\n",
    "        print(f\"Total Reward: {total_reward:0.1f}\")\n",
    "        print(f'This episode took: {(toc - tic):0.1f} sec.')\n",
    "        print('- '*15)\n",
    "        print()\n",
    "\n",
    "        tic = time.perf_counter()\n",
    "\n",
    "    total_rewards.append(total_reward)\n",
    "\n",
    "batch_q_values_collected = batch_q_values_collected[1::,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2be5a1-4c63-499a-917f-83ac580c4503",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_losses_collected = np.array(ca.MSE_losses).ravel()\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.semilogy(MSE_losses_collected)\n",
    "plt.xlabel('Epoch #', fontsize=20)\n",
    "plt.ylabel('MSE loss', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3ede3-6efc-47a2-8cff-0f8969ed4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(total_rewards, 'ko--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edbe34-a01b-41d8-8d02-d4c5838ebf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for i in range(0,5):\n",
    "    plt.plot(batch_q_values_collected[:,i], '--', label='Action ' + str(i+1), color=action_colors[i], lw=2)\n",
    "plt.xlabel('Episode #', fontsize=20)\n",
    "plt.ylabel('Q-value', fontsize=20)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea732600-f539-414d-aefd-0e71fcaec23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.online_q_network.save('QNetwork.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade1e32-5894-452f-8031-ee6383908c16",
   "metadata": {},
   "source": [
    "### Visualize the learned policy in the training environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee06b916-96b0-4533-81d8-2fc0bb3f4171",
   "metadata": {},
   "source": [
    "Create sparse samples of camera position on a uniform grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963c04c-4011-46af-8556-5c10b231448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, _, H, W) = ca.env.flowfield.velocity_field_magnitude.shape\n",
    "(H_adm, W_adm) = ca.env.admissible_observation_space\n",
    "idx_H = [i for i in range(0, H_adm) if i % 2 == 0]\n",
    "idx_W = [i for i in range(0, W_adm) if i % 2 == 0]\n",
    "print(len(idx_H) * len(idx_W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4e4e1-0566-4982-8805-9ff2b46f03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "learned_policy = np.ones((H,W)) * np.nan\n",
    "\n",
    "for h in idx_H:\n",
    "    for w in idx_W:\n",
    "\n",
    "        camera_position = np.array([h, w])\n",
    "        _, cues = ca.env.reset(imposed_camera_position=camera_position)\n",
    "        q_values = ca.online_q_network(cues)\n",
    "        action = np.argmax(q_values)\n",
    "        learned_policy[h, w] = action\n",
    "\n",
    "learned_policy = learned_policy[~np.isnan(learned_policy)]\n",
    "learned_policy = learned_policy.reshape(len(idx_H), len(idx_W))\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f'\\tTime it took: {(toc - tic):0.1f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6181d7-86ea-4b77-b644-d32deb4fb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = cmc.batlow(np.linspace(0, 1, 5))\n",
    "cmap = ListedColormap(cluster_colors)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(learned_policy, origin='lower', cmap=cmap_actions, vmin=0, vmax=4)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_ticks([4/5*(i+0.5) for i in range(0,5)])\n",
    "cbar.set_ticklabels(list(ca.env.action_to_verbose_direction.values()))\n",
    "plt.xticks([i for i in range(0,len(idx_W))], idx_W, rotation=90)\n",
    "plt.yticks([i for i in range(0,len(idx_H))], idx_H);\n",
    "plt.savefig('policy.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734e478-7256-4198-82ca-c31b9818406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = env.render(camera_position,\n",
    "                 c='white',\n",
    "                 s=20,\n",
    "                 lw=1,\n",
    "                 normalize_cbars=True,\n",
    "                 cmap=cmc.roma,\n",
    "                 add_streamplot=True,\n",
    "                 streamplot_density=3,\n",
    "                 streamplot_color='k',\n",
    "                 streamplot_linewidth=0.3,\n",
    "                 figsize=(10,6), \n",
    "                 filename='final-environment.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e9fdf-08c2-4441-a753-2613ecbb649c",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Test the trained agent on a new environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a75d3b-73a5-42ad-9832-834733294db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_spec = ParticleSpecs(diameters=(1, 1),\n",
    "                              distances=(2, 2),\n",
    "                              densities=(0.4, 0.4),\n",
    "                              diameter_std=0,\n",
    "                              seeding_mode='random')\n",
    "\n",
    "print(particle_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d234118-b279-4c62-b4d6-b32a737a5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowfield_spec = FlowFieldSpecs(size=(200,300),\n",
    "                                flowfield_type='radial',\n",
    "                                radial_epsilon=1e-6,\n",
    "                                radial_source=True,\n",
    "                                radial_sigma=20,\n",
    "                                radial_imposed_source_location=None,\n",
    "                                displacement=(2, 2))\n",
    "\n",
    "print(flowfield_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6497f-a5c5-49ef-9f6b-0e3a3bb1d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_spec = MotionSpecs(n_steps=10,\n",
    "                          time_separation=1,\n",
    "                          particle_loss=(0, 0),\n",
    "                          particle_gain=(0, 0))\n",
    "\n",
    "print(motion_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd73503-1433-4b54-8759-37de5bd4448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_spec = ImageSpecs(exposures=(0.98, 0.98),\n",
    "                        maximum_intensity=2**16-1,\n",
    "                        laser_beam_thickness=1,\n",
    "                        laser_over_exposure=1,\n",
    "                        laser_beam_shape=0.95,\n",
    "                        alpha=1/8,\n",
    "                        clip_intensities=True,\n",
    "                        normalize_intensities=False)\n",
    "\n",
    "print(image_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce179c7-e064-41c7-9afe-a49072c74f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = PIVEnv(interrogation_window_size=interrogation_window_size,\n",
    "                  interrogation_window_size_buffer=interrogation_window_size_buffer,\n",
    "                  cues_function=cues_function,\n",
    "                  particle_spec=particle_spec,\n",
    "                  motion_spec=motion_spec,\n",
    "                  image_spec=image_spec,\n",
    "                  flowfield_spec=flowfield_spec,\n",
    "                  user_flowfield=None,\n",
    "                  inference_model=None,\n",
    "                  random_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f62eb0-c782-4351-bad7-1975b346983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_position, cues = test_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c47dc-f81b-400c-84be-45e5a32b1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = test_env.render(camera_position,\n",
    "                     c='white',\n",
    "                     s=20,\n",
    "                     lw=1,\n",
    "                     normalize_cbars=True,\n",
    "                     cmap=cmc.roma,\n",
    "                     add_streamplot=True,\n",
    "                     streamplot_density=3,\n",
    "                     streamplot_color='k',\n",
    "                     streamplot_linewidth=0.3,\n",
    "                     figsize=(15,6), \n",
    "                     filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a958029c-c87c-48fc-90b3-fd7be41f9fad",
   "metadata": {},
   "source": [
    "### Visualize the learned policy in the test environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e6e9c-5d59-4f9a-8d6d-74e681bc6436",
   "metadata": {},
   "source": [
    "Create sparse samples of camera position on a uniform grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495cdc5-376d-4c91-849f-a959c1dcd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, _, H, W) = test_env.flowfield.velocity_field_magnitude.shape\n",
    "(H_adm, W_adm) = test_env.admissible_observation_space\n",
    "idx_H = [i for i in range(0, H_adm) if i % 1 == 0]\n",
    "idx_W = [i for i in range(0, W_adm) if i % 1 == 0]\n",
    "print(len(idx_H) * len(idx_W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be2f5d-91c8-4128-ba63-a7e7a0c5e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "learned_policy = np.ones((H,W)) * np.nan\n",
    "\n",
    "for h in idx_H:\n",
    "    for w in idx_W:\n",
    "\n",
    "        camera_position = np.array([h, w])\n",
    "        _, cues = test_env.reset(imposed_camera_position=camera_position)\n",
    "        q_values = ca.online_q_network(cues)\n",
    "        action = np.argmax(q_values)\n",
    "        learned_policy[h, w] = action\n",
    "\n",
    "learned_policy = learned_policy[~np.isnan(learned_policy)]\n",
    "learned_policy = learned_policy.reshape(len(idx_H), len(idx_W))\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f'\\tTime it took: {(toc - tic):0.1f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746752f7-ada1-49c4-b569-a1046e8fab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cluster_colors = cmc.batlow(np.linspace(0, 1, 5))\n",
    "cmap = ListedColormap(cluster_colors)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(learned_policy, origin='lower', cmap=cmap, vmin=0, vmax=4)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_ticks([4/5*(i+0.5) for i in range(0,5)])\n",
    "cbar.set_ticklabels(list(test_env.action_to_verbose_direction.values()))\n",
    "plt.xticks([i for i in range(0,len(idx_W))], idx_W, rotation=90)\n",
    "plt.yticks([i for i in range(0,len(idx_H))], idx_H);\n",
    "# plt.xlim([90,110])\n",
    "# plt.ylim([0,20])\n",
    "plt.savefig('tested-policy.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b608af-40a4-4f91-a8e5-85bbc0718848",
   "metadata": {},
   "source": [
    "### Visualize one sample trajectory in the test environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c8a45-59fc-40ff-a3b7-3f0969424702",
   "metadata": {},
   "source": [
    "We are going to take a number of steps in the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bced6-313b-4529-acef-912e521faab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8ac95-8140-4667-a630-726fa6a517c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_camera_trajectories = np.zeros((n_steps,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32dd6d9-6038-4243-b06c-ed9990ac525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_position, cues = test_env.reset(imposed_camera_position=(60,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a71b47-6d25-4223-8ce2-5e78bbe44965",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,n_steps):\n",
    "\n",
    "    saved_camera_trajectories[i, 0] = camera_position[0]\n",
    "    saved_camera_trajectories[i, 1] = camera_position[1]\n",
    "\n",
    "    q_values = ca.online_q_network(cues)\n",
    "\n",
    "    action = np.argmax(q_values)\n",
    "\n",
    "    print(test_env.action_to_verbose_direction[action])\n",
    "\n",
    "    camera_position, cues, reward = test_env.step(action=action,\n",
    "                                                  reward_function=reward_function,\n",
    "                                                  reward_transformation=reward_transformation,\n",
    "                                                  magnify_step=10,\n",
    "                                                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e239c85-2f49-4a0a-8b2a-193ba1ddf9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(test_env.flowfield.velocity_field,\n",
    "                saved_camera_trajectories,\n",
    "                interrogation_window_size=interrogation_window_size,\n",
    "                c_path='white',\n",
    "                c_init='white',\n",
    "                c_final='black',\n",
    "                s=20,\n",
    "                lw=2,\n",
    "                xlabel=None,\n",
    "                ylabel=None,\n",
    "                xticks=True,\n",
    "                yticks=True,\n",
    "                cmap=cmc.roma,\n",
    "                add_streamplot=True,\n",
    "                streamplot_density=4,\n",
    "                streamplot_color='k',\n",
    "                streamplot_linewidth=0.4,\n",
    "                figsize=(15,5),\n",
    "                dpi=300,\n",
    "                filename=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd7b03-fcb7-417a-9280-e12c06832778",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Upload the Q-network trained on the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50817f-cfb6-4786-92cc-a5af57558ea2",
   "metadata": {},
   "source": [
    "Upload the displacement field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca982f7-0a6f-43db-8f21-165ada3a2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/Users/kamilazdybal/GitLab-Empa/pykitPIV/CHPC/RUN-TEST/TEST-'\n",
    "# path = '/Users/kamilazdybal/GitLab-Empa/pykitPIV/scripts/TEST-'\n",
    "path = '/Users/kamilazdybal/Desktop/RUN-first-successful-non-normalized-d/large-lr-'\n",
    "\n",
    "velocity_u = pd.read_csv(path + 'final-velocity-field-u.csv', sep = ',', header=None).to_numpy()\n",
    "velocity_v = pd.read_csv(path + 'final-velocity-field-v.csv', sep = ',', header=None).to_numpy()\n",
    "\n",
    "user_velocity = np.zeros((1,2,200,300))\n",
    "user_velocity[0,0,:,:] = velocity_u\n",
    "user_velocity[0,1,:,:] = velocity_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a32743c-1fb5-4a9d-b163-3f4e1aeff7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykitPIV import FlowField\n",
    "\n",
    "user_flowfield = FlowField(n_images=1,\n",
    "                      size=(200, 300),\n",
    "                      size_buffer=0,\n",
    "                      random_seed=100)\n",
    "\n",
    "user_flowfield.upload_velocity_field(user_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd373e8c-f47a-4474-9b43-8371335c6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowfield_spec = FlowFieldSpecs(size=(100, 100),\n",
    "                                flowfield_type='random smooth',\n",
    "                                gaussian_filters=(10, 10),\n",
    "                                n_gaussian_filter_iter=10,\n",
    "                                displacement=(2, 2))\n",
    "\n",
    "print(flowfield_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc81402-84e1-4bed-ab54-9b812b306707",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PIVEnv(interrogation_window_size=interrogation_window_size,\n",
    "             interrogation_window_size_buffer=0,\n",
    "             cues_function=cues_function,\n",
    "             particle_spec=particle_spec,\n",
    "             motion_spec=motion_spec,\n",
    "             image_spec=image_spec,\n",
    "             flowfield_spec=flowfield_spec,\n",
    "             inference_model=None,\n",
    "             user_flowfield=None,\n",
    "             random_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284de897-4497-4e67-a185-f6836ecb7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_position, cues = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f84a85-73ec-424c-a329-0a5c23b2ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ff6bc-4714-46d6-90c6-00148fb0fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = env.render(camera_position,\n",
    "                 c='white',\n",
    "                 s=20,\n",
    "                 lw=1,\n",
    "                 normalize_cbars=True,\n",
    "                 cmap=cmc.roma_r,\n",
    "                 add_streamplot=True,\n",
    "                 streamplot_density=3,\n",
    "                 streamplot_color='k',\n",
    "                 streamplot_linewidth=0.3,\n",
    "                 figsize=(10,6), \n",
    "                 filename='final-environment.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891a4de-4bd2-456c-86f9-3da4d76e1ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286cae1-961f-4418-b1cc-5598316ab280",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_q_network = QNetwork(n_actions=env.n_actions, kernel_initializer = tf.keras.initializers.RandomUniform)\n",
    "_ = trained_q_network(tf.ones((1, env.n_cues)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a475c22-6bfa-4992-b570-45318ff95768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_q_network.load_weights('QNetwork.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a83c49a-d999-432d-91ff-e01f27f0cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_q_network.load_weights(path + 'QNetwork.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d797e3-380a-41d4-a31a-a4a315fe2e28",
   "metadata": {},
   "source": [
    "Make inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24667c65-ad01-4703-8c84-b9a81be5210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, _, H, W) = env.flowfield.velocity_field_magnitude.shape\n",
    "(H_adm, W_adm) = env.admissible_observation_space\n",
    "idx_H = [i for i in range(0, H_adm) if i % 1 == 0]\n",
    "idx_W = [i for i in range(0, W_adm) if i % 1 == 0]\n",
    "print(len(idx_H) * len(idx_W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944e30c-48e4-468e-af17-751ba77ec5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "learned_policy = np.ones((H,W)) * np.nan\n",
    "\n",
    "for h in idx_H:\n",
    "    for w in idx_W:\n",
    "\n",
    "        camera_position = np.array([h, w])\n",
    "        _, cues = env.reset(imposed_camera_position=camera_position)\n",
    "        q_values = trained_q_network(cues)\n",
    "        action = np.argmax(q_values)\n",
    "        learned_policy[h, w] = action\n",
    "\n",
    "learned_policy = learned_policy[~np.isnan(learned_policy)]\n",
    "learned_policy = learned_policy.reshape(len(idx_H), len(idx_W))\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f'\\tTime it took: {(toc - tic):0.1f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a01fb2f-e605-43d0-9fe3-a8bc6df6746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(learned_policy, origin='lower', cmap=cmap_actions, vmin=0, vmax=4)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_ticks([4/5*(i+0.5) for i in range(0,5)])\n",
    "cbar.set_ticklabels(list(env.action_to_verbose_direction.values()))\n",
    "# plt.xticks([i for i in range(0,len(idx_W))], idx_W, rotation=90)\n",
    "# plt.yticks([i for i in range(0,len(idx_H))], idx_H);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f6565-17de-451a-84ab-a4857f44cb4e",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "© K. Zdybał, C. Mucignat, S. Kunz, I. Lunati (2025)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
