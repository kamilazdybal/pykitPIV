{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3334ff70-add2-4d60-ab1a-d1bc3dd501d7",
   "metadata": {},
   "source": [
    "<a id=top-page></a>\n",
    "\n",
    "# `pykitPIV` demo: Train a convolutional variational autoencoder\n",
    "\n",
    "In this Jupyter notebook, we show how the available functionalities from the machine learning module (`pykitPIV.ml`) can be used to train a convolutional variational autoencoder (CVAE). The trained CVAE model generates new velocity fields ($u$ and $v$ components) that belong to the distribution of some experimental data. Hence, this approach can be used to extend the training data for transfer learning and can help adapt a machine learning model to the changing experimental conditions.\n",
    "\n",
    "This tutorial was built from: https://www.tensorflow.org/tutorials/generative/cvae.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<font size=\"3\"><strong>Table of contents:</strong></font>\n",
    "<br>\n",
    "<ol>\n",
    "    <li><a href=\"#training-data\">Create/load training data</a></li>\n",
    "</ol>\n",
    "<p></p>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9634c100-9f76-41ac-b37e-37abedecddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 13:42:31.385861: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cmcrameri.cm as cmc\n",
    "from pykitPIV import PIVDatasetPyTorch\n",
    "from IPython import display\n",
    "import glob\n",
    "import imageio\n",
    "import PIL\n",
    "import time\n",
    "from pykitPIV import FlowField, Image, PIVCVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f99de3a-ec97-4153-a4e5-fd787629f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images = False\n",
    "filename = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52c6297-88db-4342-9599-6fddbde8f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cmc.oslo_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24097a75-9245-4f5d-8e8b-8dae0be0c02d",
   "metadata": {},
   "source": [
    "<a id=training-data></a>\n",
    "\n",
    "***\n",
    "\n",
    "## Create/load training data\n",
    "\n",
    "[Go to the top](#top-page)\n",
    "\n",
    "Below, we create dummy training data (displacement fields), which can be replaced by data coming from an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a6a14-443d-4f3a-94a6-0dce0ced9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 10000\n",
    "size = (28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32982162-04a6-469b-8007-4e31fb7fb847",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowfield = FlowField(n_images=n_images,\n",
    "                      size=size,\n",
    "                      size_buffer=0,\n",
    "                      time_separation=1,\n",
    "                      dtype=np.float32,\n",
    "                      random_seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ae2ef-ae27-4bdb-af35-351f6311b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "flowfield.generate_random_velocity_field(displacement=(1, 1),\n",
    "                                         gaussian_filters=(5, 10),\n",
    "                                         n_gaussian_filter_iter=3)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Total time: {(toc - tic)/60:0.1f} minutes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8071a60d-468e-4aea-a774-a8f86357610d",
   "metadata": {},
   "source": [
    "Inspect the training displacement field components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688c47e-d5e7-401a-ba6a-c5cf474c303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31775d56-7f6c-44fc-b831-808d8d7fda31",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.add_flowfield(flowfield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d031b-ce1b-4526-a266-b90d1f1c2fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.plot_field(4,\n",
    "                 field='velocity',\n",
    "                 with_buffer=True,\n",
    "                 xlabel='Width [px]',\n",
    "                 ylabel='Height [px]',\n",
    "                 title=('$dx$', '$dy$'),\n",
    "                 cmap=cmc.oslo_r,\n",
    "                 cbar=True,\n",
    "                 origin='lower',\n",
    "                 figsize=(3,3),\n",
    "                 filename=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02951b2e-6b6c-4dcc-8061-072b3f0a5c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.plot_field_magnitude(7,\n",
    "                 field='velocity',\n",
    "                 with_buffer=True,\n",
    "                 xlabel='Width [px]',\n",
    "                 ylabel='Height [px]',\n",
    "                 cmap=cmc.oslo_r,\n",
    "                 cbar=True,\n",
    "                 figsize=(3,3),\n",
    "                 filename=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf8e07-4da2-4354-bd27-fa26bb2fd545",
   "metadata": {},
   "source": [
    "### Prepare training data for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54db221-4732-4b87-b4b8-87063b07216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_at = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9eeb5d-208e-46c6-9b0d-eb8e0588af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_field = flowfield.velocity_field\n",
    "\n",
    "for i in range(0, n_images):\n",
    "\n",
    "    vector_field[i, 0, :, :] = vector_field[i, 0, :, :] - np.min(vector_field[i, 0, :, :])\n",
    "    vector_field[i, 0, :, :] = vector_field[i, 0, :, :] / np.max(vector_field[i, 0, :, :])\n",
    "    \n",
    "    vector_field[i, 1, :, :] = vector_field[i, 1, :, :] - np.min(vector_field[i, 1, :, :])\n",
    "    vector_field[i, 1, :, :] = vector_field[i, 1, :, :] / np.max(vector_field[i, 1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea496d-2e69-4f6f-ab75-34067326c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = vector_field[0:split_at,:,:,:]\n",
    "test_images = vector_field[split_at::,:,:,:]\n",
    "\n",
    "train_images = np.transpose(train_images, (0, 2, 3, 1))\n",
    "test_images = np.transpose(test_images, (0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c89d98-3166-4dd4-a898-50278305bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149975d6-818a-4775-83c9-32918a89d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc9362a-f3bd-4004-9c9c-b09dd5d9a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = train_images.shape[0]\n",
    "batch_size = 32\n",
    "test_size = test_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16117e3-49ff-4afa-9eb0-29f93dce2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices(train_images).shuffle(train_size).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(test_images).shuffle(test_size).batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc21e30-d02b-48bf-9e2b-b6d242f38d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e5c99-22c5-42df-b117-4c9943475262",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Parameters of the convolutional variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63474583-dd11-4e11-9258-14c9f33a8a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2aefa1-e877-409b-b2e0-fda22f48297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (size[0], size[1], n_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ed9fc-64c5-4860-8385-666eddd59e88",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Train the variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712778b-2a5d-400e-9404-b85716a690f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076ed6c-5d18-4384-a1d7-910552ed3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 2\n",
    "\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(shape=[num_examples_to_generate, latent_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1282019-9f8c-4515-a053-8cf51c40aaa5",
   "metadata": {},
   "source": [
    "Initialize the convolutional autoencoder as a `pykitPIV.ml.PIVCVAE` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40919d1-208e-471b-aad1-fd865dd145f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PIVCVAE(input_shape=input_shape, \n",
    "                latent_dimension=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086e029-16af-4c9c-89bb-089ddef8ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "    \n",
    "  mean, logvar = model.encode(test_sample)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  predictions = model.sample(z)\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      \n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(predictions[i, :, :, 0], cmap=cmap)\n",
    "    plt.axis('off')\n",
    "\n",
    "  # tight_layout minimizes the overlap between 2 sub-plots\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a544a6a-51f4-44cb-ac2f-64eb3cfbb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a sample of the test set for generating output images\n",
    "assert batch_size >= num_examples_to_generate\n",
    "for test_batch in test_dataset.take(1):\n",
    "  test_sample = test_batch[0:num_examples_to_generate, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ffba8-380d-4442-9d7e-c8cbdff4f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_images(model, 0, test_sample)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for train_x in train_dataset:\n",
    "        train_step(model, train_x, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    \n",
    "    for test_x in test_dataset:\n",
    "        loss(compute_loss(model, test_x))\n",
    "      \n",
    "    elbo = -loss.result()\n",
    "    \n",
    "    display.clear_output(wait=False)\n",
    "    \n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'.format(epoch, elbo, end_time - start_time))\n",
    "    \n",
    "    generate_and_save_images(model, epoch, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3976d3-2b05-4224-96cd-6cd53e0d3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916b05c-d46e-4008-9ed0-f3628ff9a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(display_image(epoch))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360dac15-ef00-4515-ad30-f68065373a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'cvae.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image_for_gif = imageio.imread(filename)\n",
    "    writer.append_data(image_for_gif)\n",
    "  image_for_gif = imageio.imread(filename)\n",
    "  writer.append_data(image_for_gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14150a9-9284-4548-a5bf-6302cb30af9a",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "© K. Zdybał, C. Mucignat, S. Kunz, I. Lunati (2025)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
