{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603d26ae-d712-41bf-9990-92c4248bf185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms\n",
    "from rich import print\n",
    "from torch.utils.data import DataLoader\n",
    "import lima\n",
    "import glob\n",
    "import h5py\n",
    "import skimage.io as io\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cmcrameri.cm as cmc\n",
    "from pykitPIV import Particle, FlowField, Motion, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930baf11-22a4-4492-a616-8c87e77117fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.10</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3.10\u001b[0m.\u001b[1;36m14\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8ddabf-9694-4584-9043-157cca33d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_of_images = 65535.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdedc10-9e08-447d-9e9f-55aea1ff9a31",
   "metadata": {},
   "source": [
    "<a id=synthetic-images></a>\n",
    "\n",
    "***\n",
    "\n",
    "## Generate synthetic images with `pykitPIV`\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa469657-bb96-40e8-b865-2616be55b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (124,124)\n",
    "size_buffer = 10\n",
    "figsize = (5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e85233-0a70-421a-98a3-56ed768867a2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_images(n_images, random_seed):\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    # Instantiate an object of the Particle class:\n",
    "    particles = Particle(n_images,\n",
    "                         size=image_size,\n",
    "                         size_buffer=size_buffer,\n",
    "                         diameters=(4,4.1),\n",
    "                         distances=(1,2),\n",
    "                         densities=(0.05,0.1),\n",
    "                         signal_to_noise=(5,20),\n",
    "                         diameter_std=0.2,\n",
    "                         seeding_mode='random',\n",
    "                         random_seed=random_seed)\n",
    "\n",
    "    # Instantiate an object of the FlowField class:\n",
    "    flowfield = FlowField(n_images,\n",
    "                          size=image_size,\n",
    "                          size_buffer=size_buffer,\n",
    "                          random_seed=random_seed)\n",
    "\n",
    "    flowfield.generate_random_velocity_field(gaussian_filters=(10,11),\n",
    "                                             n_gaussian_filter_iter=20,\n",
    "                                             displacement=(0,10))\n",
    "\n",
    "    # Instantiate an object of the Motion class:\n",
    "    motion = Motion(particles, \n",
    "                    flowfield, \n",
    "                    time_separation=0.1)\n",
    "\n",
    "    # Advect particles:\n",
    "    motion.forward_euler(n_steps=10)\n",
    "\n",
    "    # Instantiate an object of the Image class:\n",
    "    image = Image(random_seed=random_seed)\n",
    "\n",
    "    # Prepare images - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "    image.add_particles(particles)\n",
    "\n",
    "    image.add_flowfield(flowfield)\n",
    "  \n",
    "    image.add_motion(motion)\n",
    "    \n",
    "    image.add_reflected_light(exposures=(0.7,0.8),\n",
    "                              maximum_intensity=2**16-1,\n",
    "                              laser_beam_thickness=1,\n",
    "                              laser_over_exposure=1,\n",
    "                              laser_beam_shape=0.95,\n",
    "                              alpha=1/10)\n",
    "\n",
    "    image.remove_buffers()\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    print(f'Time it took: {(toc - tic)/60:0.1f} minutes.\\n')\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc64d21f-c1fe-4750-ac1c-f35d67a432c2",
   "metadata": {},
   "source": [
    "<a id=synthetic-images-training-set></a>\n",
    "\n",
    "### Training set\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa253c-0507-48b3-928b-46f2a5c0e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_images = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f99854-fe8b-4851-8f3a-7f8d7c6b09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_random_seed = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476aa953-6f12-40cc-ae46-042d84103067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_train = generate_images(n_images, training_random_seed)\n",
    "\n",
    "# image_pairs_train = image_train.image_pairs_to_tensor()\n",
    "# targets_train = image_train.targets_to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517fd67-1615-4b1c-b3e2-77ff8f2dd42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_train.save_to_h5({'I': image_pairs_train, 'targets': targets_train}, filename='PIV-dataset-train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8cb11-d2a7-4083-abb0-a8629b180052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_train.plot(0,\n",
    "#                  instance=1,\n",
    "#                  with_buffer=True,\n",
    "#                  xlabel='Width [px]',\n",
    "#                  ylabel='Height [px]',\n",
    "#                  cmap='Greys_r',\n",
    "#                  figsize=figsize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259149b-49f5-4100-a89a-880831724060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_of_images = np.max(image_pairs_train)\n",
    "# max_of_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b7a28-04ed-45a7-9085-082f14d94cd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a id=synthetic-images-testing-set></a>\n",
    "\n",
    "### Testing set\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f510c1b-b8c1-49a4-8e61-67bb13e48fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_images = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668f73b-c0c5-42c5-899a-82e72b8098cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_random_seed = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba806bc8-82cd-4211-8a7e-cc4486753d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_test = generate_images(n_images, test_random_seed)\n",
    "\n",
    "# image_pairs_test = image_test.image_pairs_to_tensor()\n",
    "# targets_test = image_test.targets_to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731c641-51f4-4022-bc22-37ff603c5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_train.save_to_h5({'I': image_pairs_test, 'targets': targets_test}, filename='PIV-dataset-test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1a1d6-7745-4551-85f8-c4eea982cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_test.plot(0,\n",
    "#                 instance=1,\n",
    "#                 with_buffer=True,\n",
    "#                 xlabel='Width [px]',\n",
    "#                 ylabel='Height [px]',\n",
    "#                 cmap='Greys_r',\n",
    "#                 figsize=figsize);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9529ac-04f7-45a7-b392-8bc7b6379c8a",
   "metadata": {},
   "source": [
    "<a id=train-LIMA></a>\n",
    "***\n",
    "\n",
    "## Train `LIMA` with the generated images\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7e34e-b9d5-4801-bdb1-8edd07ccd4c3",
   "metadata": {},
   "source": [
    "<a id=train-LIMA-input-data></a>\n",
    "### Prepare input dataset for LIMA\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b01577-ff6f-4dc7-8fde-fc9f02cbea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([lima.datatransform.RandomAffine(degrees=17, translate=(0.2, 0.2), scale=(0.9, 2.0)),\n",
    "                                            lima.datatransform.RandomHorizontalFlip(),\n",
    "                                            lima.datatransform.RandomVerticalFlip(),\n",
    "                                            lima.datatransform.ToTensor(),\n",
    "                                            lima.datatransform.RandomBrightness(factor=(0.5, 2)),\n",
    "                                            lima.datatransform.RandomNoise(std=(0, 0)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c90ec29-01b5-474f-9b2e-a590a955d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([lima.datatransform.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb78a4-858c-4864-b76f-18dd4af76a89",
   "metadata": {},
   "source": [
    "#### Use dataset generated on-the-fly with `pykitPIV`:\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e705b1-cc07-44e1-8ea0-27e9d4d046db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class pykitPIVDataset(Dataset):\n",
    "#     \"\"\"Load pykitPIV-generated dataset\"\"\"\n",
    "\n",
    "#     def __init__(self, image_pairs, targets, transform=None, n_samples=None, pin_to_ram=False):\n",
    "\n",
    "#         self.data = image_pairs.astype(np.float32)\n",
    "#         self.target = targets.astype(np.float32)\n",
    "\n",
    "#         if n_samples:\n",
    "#             self.data = self.data[:n_samples]\n",
    "#             self.target = self.target[:n_samples]\n",
    "#         if pin_to_ram:\n",
    "#             self.data = np.array(self.data)\n",
    "#             self.target = np.array(self.target)\n",
    "\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "#         sample = self.data[idx], self.target[idx]\n",
    "#         if self.transform:\n",
    "#             sample = self.transform(sample)\n",
    "\n",
    "#         return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e9992-d893-465a-9771-5d7731d75c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = pykitPIVDataset(image_pairs=image_pairs_train/max_of_images,\n",
    "#                                 targets=targets_train,\n",
    "#                                 transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f81ad-1d42-441d-96e1-15eb95471a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = pykitPIVDataset(image_pairs=image_pairs_test/max_of_images,\n",
    "#                                 targets=targets_test,\n",
    "#                                 transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb75850-05f9-48e7-bd0d-b284e6f4c043",
   "metadata": {},
   "source": [
    "#### Use a pre-saved dataset generated with `pykitPIV`:\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04df0096-f682-4e71-862d-99b77790e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pykitPIVDatasetFromPath(Dataset):\n",
    "    \"\"\"Load pykitPIV-generated dataset\"\"\"\n",
    "\n",
    "    def __init__(self, path, transform=None, n_samples=None, pin_to_ram=False):\n",
    "        \n",
    "        f = h5py.File(path, \"r\")\n",
    "        self.data = np.array(f[\"I\"]).astype(np.float32)/max_of_images\n",
    "        self.target = np.array(f[\"targets\"]).astype(np.float32)\n",
    "\n",
    "        print(self.target.max())\n",
    "\n",
    "        if n_samples:\n",
    "            self.data = self.data[:n_samples]\n",
    "            self.target = self.target[:n_samples]\n",
    "            \n",
    "        if pin_to_ram:\n",
    "            self.data = np.array(self.data)\n",
    "            self.target = np.array(self.target)\n",
    "            f.close()\n",
    "            \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        sample = self.data[idx], self.target[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c456ab-4b17-4ba8-8bb3-6347a523da4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.523903</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m9.523903\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = pykitPIVDatasetFromPath(path='PIV-dataset-train.h5',\n",
    "                                        transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d86dd3-562b-43b9-9e4a-257ad8c7d89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.988755</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m8.988755\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = pykitPIVDatasetFromPath(path='PIV-dataset-test.h5',\n",
    "                                       transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c38dcc-9ca2-4e76-b7b3-031e9bfb180d",
   "metadata": {},
   "source": [
    "#### Use dataset generated with Matlab:\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5074828-00b9-455c-bced-0efbb430f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'PIV_n3_s180_maxd10_rnd_v1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc9631-f90f-4ff5-b82f-8305e7be51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = h5py.File(path, \"r\")\n",
    "\n",
    "# images = f[\"I\"]\n",
    "# images = np.array(images)\n",
    "# targets = f[\"target\"]\n",
    "# targets = np.array(targets)[:,2:4,:,:]\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce131801-974f-404e-a402-52aebd83a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.array(images)[0,0,:,:], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68a329-5720-49b1-8a89-e1f7793e0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HDF5Dataset(Dataset):\n",
    "#     \"\"\"HDF5Dataset loaded\"\"\"\n",
    "\n",
    "#     def __init__(self, path, transform=None, n_samples=None, pin_to_ram=False):\n",
    "#         f = h5py.File(path, \"r\")\n",
    "#         self.data = f[\"I\"]\n",
    "#         self.target = np.array(f[\"target\"])[:,2:4,:,:]\n",
    "\n",
    "#         if n_samples:\n",
    "#             self.data = self.data[:n_samples]\n",
    "#             self.target = self.target[:n_samples]\n",
    "#         if pin_to_ram:\n",
    "#             self.data = np.array(self.data)\n",
    "#             self.target = np.array(self.target)\n",
    "#             f.close()\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "#         sample = self.data[idx], self.target[idx]\n",
    "#         if self.transform:\n",
    "#             sample = self.transform(sample)\n",
    "\n",
    "#         return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd2f0d-3ebc-4cd9-ae9a-276a418056d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = HDF5Dataset(path=path,\n",
    "#                             transform=transform,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35612cb1-32d0-4fbe-a59b-e292b8ad365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = HDF5Dataset(path=path,\n",
    "#                            transform=transform,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b64556-51d8-44b3-8de8-d8ee1d0e93c5",
   "metadata": {},
   "source": [
    "<a id=train-LIMA-train></a>\n",
    "### Begin training\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f26a0fb-5c98-4b92-b28d-8fbc52b7e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=5,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1,\n",
    "                          pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "284c02df-f0b8-4468-a52b-eb64f8c9cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c371af-27e4-46ff-8c54-20658c8ba1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(random_seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c313fe7e-3496-4630-b61e-9a6508f525c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lima.LIMA(output_level=1,\n",
    "                  div_flow=0.05,\n",
    "                  loss_weights=[0.005,0.01,0.02,0.04,0.08,0.04,0.04],\n",
    "                  search_range=4,\n",
    "                  num_chs=[1, 16, 32, 64, 96, 128, 196],\n",
    "                  loss='l1_loss',\n",
    "                  loss_weights_order='inc',\n",
    "                  loss_J='abs',\n",
    "                  loss_J_gamma=1e-1,\n",
    "                  full_res=False,\n",
    "                  full_res_loss_weight_multiplier=2.0,\n",
    "                  epochs=10,\n",
    "                  optimizer='Adam',\n",
    "                  base_lr=0.001,\n",
    "                  weight_decay=4e-4,\n",
    "                  momentum=0.9,\n",
    "                  num_workers=20,\n",
    "                  beta=0.999,\n",
    "                  reduction=\"sum\",\n",
    "                  scheduler='ReduceLROnPlateau',\n",
    "                  lr_decay=0.2,\n",
    "                  patience=5,\n",
    "                  debug=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "435118b5-496e-484f-b46a-7da508796b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdka/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b85c26e-e5af-423c-bf74-ef51f540c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27093e8b-3395-4e01-adc5-0857d7f0830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdka/.local/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "/home/zdka/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name                      | Type             | Params\n",
      "---------------------------------------------------------------\n",
      "0 | feature_pyramid_extractor | FeatureExtractor | 1.0 M \n",
      "1 | warping_layer             | WarpingLayer     | 0     \n",
      "2 | flow_estimators           | ContextNetwork   | 576 K \n",
      "---------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.466     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|                                                                                                                                      | 0/2 [00:00<?, ?it/s]torch.Size([10, 81, 2, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdka/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 81, 4, 4])\n",
      "Sanity Checking DataLoader 0:  50%|███████████████████████████████████████████████████████████████                                                               | 1/2 [00:00<00:00,  3.73it/s]torch.Size([10, 81, 2, 2])\n",
      "torch.Size([10, 81, 4, 4])\n",
      "                                                                                                                                                                                               "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdka/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/zdka/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1595: PossibleUserWarning: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                                                                                          | 0/22 [00:00<?, ?it/s]*** LIMA  Data:: torch.float32 cpu    ****\n",
      "torch.Size([5, 81, 2, 2])\n",
      "torch.Size([5, 81, 4, 4])\n",
      "Epoch 0:   5%|████▎                                                                                           | 1/22 [00:09<03:12,  9.16s/it, loss=6.44e+04, v_num=56, train_loss_step=6.44e+4]torch.Size([5, 81, 2, 2])\n",
      "torch.Size([5, 81, 4, 4])\n",
      "Epoch 0:   9%|████████▋                                                                                       | 2/22 [00:13<02:16,  6.84s/it, loss=8.01e+04, v_num=56, train_loss_step=95745.5]torch.Size([5, 81, 2, 2])\n",
      "torch.Size([5, 81, 4, 4])\n",
      "Epoch 0:  14%|█████████████▏                                                                                   | 3/22 [00:18<01:55,  6.08s/it, loss=6.3e+04, v_num=56, train_loss_step=2.87e+4]torch.Size([5, 81, 2, 2])\n",
      "torch.Size([5, 81, 4, 4])\n",
      "Epoch 0:  18%|█████████████████▍                                                                              | 4/22 [00:22<01:42,  5.71s/it, loss=5.11e+04, v_num=56, train_loss_step=1.55e+4]torch.Size([5, 81, 2, 2])\n",
      "torch.Size([5, 81, 4, 4])\n",
      "Epoch 0:  23%|█████████████████████▊                                                                          | 5/22 [00:27<01:33,  5.48s/it, loss=4.23e+04, v_num=56, train_loss_step=7.16e+3]torch.Size([5, 81, 2, 2])\n",
      "torch.Size([5, 81, 4, 4])\n",
      "Epoch 0:  27%|██████████████████████████▏                                                                     | 6/22 [00:31<01:25,  5.32s/it, loss=3.63e+04, v_num=56, train_loss_step=6.49e+3]torch.Size([5, 81, 2, 2])\n",
      "torch.Size([5, 81, 4, 4])\n",
      "Epoch 0:  32%|██████████████████████████████▌                                                                 | 7/22 [00:36<01:18,  5.23s/it, loss=3.15e+04, v_num=56, train_loss_step=2.83e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zdka/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,\n",
    "            train_loader,\n",
    "            test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c376df4-1cf6-4a4a-a449-97616f514056",
   "metadata": {},
   "source": [
    "<a id=predict></a>\n",
    "***\n",
    "\n",
    "## Make predictions from the trained network\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf674b-a2d3-4bd3-99ef-f2bfd8ce8316",
   "metadata": {},
   "source": [
    "Switch to the evaluation mode of the LIMA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187a3b3-1617-413b-807b-45a3cd3d62a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf0a00f-d8af-490f-ba71-f2ef67952347",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_predict = 0\n",
    "velocity_component = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c812b-c5e3-4620-a6a2-841e1e506167",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_flow = model.inference(image_pairs_train[:,:,:,:].astype(np.float32)/max_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc08a7-65d5-4b9a-9a89-ffa483b70e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_flow = model.inference(train_dataset.data[:,:,:,:].astype(np.float32)/max_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec9ae3-538a-4ac4-8035-ecd25c45cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_flow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997520a-9f66-4985-be8b-a9739d0f53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d5457-9802-4155-a92a-68376091fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted_flow[image_to_predict,velocity_component,:,:], \n",
    "           cmap=cmc.batlow, \n",
    "           origin='lower')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf324ff8-419c-4ef6-a0f5-6319e8ad80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_dataset.target[image_to_predict,velocity_component,:,:], \n",
    "           cmap=cmc.batlow, \n",
    "           origin='lower')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e8cbcf-4979-4ea2-a50e-1eeedc48977d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b941959-74a9-4f1c-b441-84e3f8d3fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,1,100,100), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639c07a-1d3c-4ae2-8c7b-84190ef6033f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85ecfc-1d62-48d3-90f5-5bfafc7f6929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd1e47-2963-4f65-9516-ddf30ccf9689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa013f14-ebe2-4309-8dba-07913727669e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "812e3354-4736-4c34-8d7f-4cc26d7b565e",
   "metadata": {},
   "source": [
    "#### Predict from a random tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7fab0-c688-47a3-a6ee-9062f69b9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10, 2, 100, 100).cpu()\n",
    "predicted_flow = model.inference(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e317099-e881-4a90-a014-b17144e4efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_flow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ff229-66f7-4ffb-8b30-52ccd1d24309",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted_flow[0,0,:,:], \n",
    "           cmap=cmc.batlow, \n",
    "           origin='lower')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb3fb9-edee-4317-804a-a81600b35a0e",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
