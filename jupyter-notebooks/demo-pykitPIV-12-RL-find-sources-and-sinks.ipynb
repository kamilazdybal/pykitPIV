{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28fed105-acc8-4b6f-962e-95c044f24d47",
   "metadata": {},
   "source": [
    "<a id=top-page></a>\n",
    "# `pykitPIV` demo: Learn to find sources and sinks in a 2D PIV experiment using reinforcement learning\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<font size=\"3\"><strong>Table of contents:</strong></font>\n",
    "<br>\n",
    "<ol>\n",
    "\n",
    "</ol>\n",
    "<p></p>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442604c-be37-4b9a-8c1c-0c08c717d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykitPIV.ml import PIVEnv, CameraAgent, Rewards, Cues, plot_trajectory\n",
    "from pykitPIV.flowfield import compute_q_criterion, compute_divergence\n",
    "from pykitPIV import ParticleSpecs, FlowFieldSpecs, MotionSpecs, ImageSpecs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cmcrameri.cm as cmc\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import sys, os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc6559-5d5a-45f7-984c-245eb6f73a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrogation_window_size = (50,60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06129ede-9b88-4793-a8a1-95065bddc272",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5541e-15bd-420c-9cce-55d4ffabf8c6",
   "metadata": {},
   "source": [
    "### Prepare specifications for pykitPIV parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0797d34e-fec2-4aae-9376-d9a2d09bfa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_spec = ParticleSpecs(diameters=(1, 1),\n",
    "                              distances=(2, 2),\n",
    "                              densities=(0.4, 0.4),\n",
    "                              diameter_std=0,\n",
    "                              seeding_mode='random')\n",
    "\n",
    "print(particle_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beca1f3-4e59-41e0-b55c-064b9ff5a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowfield_spec = FlowFieldSpecs(size=(200, 300),\n",
    "                                flowfield_type='random smooth',\n",
    "                                gaussian_filters=(10, 10),\n",
    "                                n_gaussian_filter_iter=10,\n",
    "                                displacement=(2, 2))\n",
    "\n",
    "print(flowfield_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11035f5-11be-4ae2-84bd-8d1c380b110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_spec = MotionSpecs(n_steps=10,\n",
    "                          time_separation=1,\n",
    "                          particle_loss=(0, 0),\n",
    "                          particle_gain=(0, 0))\n",
    "\n",
    "print(motion_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9559313-6085-4dd9-b912-db94ca05407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_spec = ImageSpecs(exposures=(0.98, 0.98),\n",
    "                        maximum_intensity=2**16-1,\n",
    "                        laser_beam_thickness=1,\n",
    "                        laser_over_exposure=1,\n",
    "                        laser_beam_shape=0.95,\n",
    "                        alpha=1/8,\n",
    "                        clip_intensities=True,\n",
    "                        normalize_intensities=False)\n",
    "\n",
    "print(image_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d1764-2e92-4ae1-807c-4971131005b4",
   "metadata": {},
   "source": [
    "### Prepare the CNN-based inference model for PIV images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fc888-c3da-49fd-87b2-ca0f4990848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ONNXmodel:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 onnx_file_path):\n",
    "        \n",
    "        self.name = \"ONNX\"\n",
    "        self.providers = ['CPUExecutionProvider']\n",
    "        self.session = onnxruntime.InferenceSession(onnx_file_path, \n",
    "                                                    None,\n",
    "                                                    providers=self.providers)\n",
    "\n",
    "        self.input_name = self.session.get_inputs()[0].name  \n",
    "        print('Input Name:', self.input_name)   \n",
    " \n",
    "    def inference(self, x):\n",
    "        \n",
    "        output = self.session.run([], {self.input_name:x/np.max(x)})[0] \n",
    "      \n",
    "        return output\n",
    "\n",
    "    def empty(self):\n",
    "        \n",
    "         with torch.no_grad():\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1814c-d029-4ad0-95f0-6382f6213ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = '../Lima_L4_PAD_SR2_dyn.onnx'\n",
    "print(\"model:\", model_file, '  exist:', os.path.exists(model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814774a-3919-498d-b2fd-0217b634d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "lima_inference_model = ONNXmodel(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b2b6b-1c9c-4d00-ab01-6fc7c9d9776d",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Create the RL environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce70f4-bde4-4e38-814e-e31db23c08d2",
   "metadata": {},
   "source": [
    "Define the cues that the RL agent effectively senses and learns from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e534d67-2751-40bd-8a48-cae84aad63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cues_obj = Cues()\n",
    "cues_function = cues_obj.sampled_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca8abad-37f7-41c3-ab8b-22f1073b5f0b",
   "metadata": {},
   "source": [
    "Initialize the `Gymnasium` environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30205c9-39af-47d6-a5d8-c94ac070abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PIVEnv(interrogation_window_size=interrogation_window_size,\n",
    "             interrogation_window_size_buffer=5,\n",
    "             cues_function=cues_function,\n",
    "             particle_spec=particle_spec,\n",
    "             motion_spec=motion_spec,\n",
    "             image_spec=image_spec,\n",
    "             flowfield_spec=flowfield_spec,\n",
    "             inference_model=None,\n",
    "             random_seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e32c09-2148-436c-a847-5be93015ec19",
   "metadata": {},
   "source": [
    "Reset the environment to prepare its intial state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a58032-e56f-4a8c-bacc-16a82bc38d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_position, cues = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f945c-247a-4fa4-abfe-0b5747db791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = env.render(camera_position,\n",
    "                 c='white',\n",
    "                 s=20,\n",
    "                 lw=1,\n",
    "                 normalize_cbars=True,\n",
    "                 cmap=cmc.roma,\n",
    "                 add_streamplot=True,\n",
    "                 streamplot_density=3,\n",
    "                 streamplot_color='k',\n",
    "                 streamplot_linewidth=0.3,\n",
    "                 figsize=(10,6), \n",
    "                 filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89f432-4274-4f50-b116-85aac1550f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "div = compute_divergence(env.flowfield.velocity_field, edge_order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977c16a-2013-4a18-817a-80e7f2ed2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(div[0,:,:], origin='lower', cmap='coolwarm')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7569c7-d9f5-4a6a-be8f-e2178e3fe7c3",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Create and train the RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20fc7f1-ee6e-4c57-bb0d-bea7a238992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 10\n",
    "n_iterations = 10\n",
    "\n",
    "epsilon_start = 0.8\n",
    "discount_factor=0.95\n",
    "\n",
    "batch_size = 128\n",
    "memory_size = 10000\n",
    "n_epochs = 1\n",
    "\n",
    "initial_learning_rate = 0.0001\n",
    "alpha_lr = 0.0001\n",
    "kernel_initializer = tf.keras.initializers.Ones\n",
    "\n",
    "n_decay_steps = int(n_episodes/1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d0870-32fe-4761-99b8-8ba22c592cc6",
   "metadata": {},
   "source": [
    "Define the exploration probability decay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c072a-edc0-45d3-86f2-b4c9c5c75f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_exp_decay(epsilon_start, iter_count, n=1000):\n",
    "    return epsilon_start/np.exp(iter_count/(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950cfb22-7bbf-4e62-ba83-bdec061932cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_probabilities = []\n",
    "\n",
    "for i in range(0,1000):\n",
    "\n",
    "    exploration_probabilities.append(epsilon_exp_decay(epsilon_start, i, n=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecfe9a3-ac06-4913-b307-75dd8dc0acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,2))\n",
    "plt.plot(exploration_probabilities, c='k', lw=3);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f5d2d-8081-4c83-a864-64af17ea1dff",
   "metadata": {},
   "source": [
    "Define the Q-network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140daefe-d0d6-47f3-8017-6338936024bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, n_actions, kernel_initializer):\n",
    "        \n",
    "        super(QNetwork, self).__init__()\n",
    "        \n",
    "        self.dense1 = tf.keras.layers.Dense(15, activation='linear', kernel_initializer=kernel_initializer)\n",
    "        self.dense2 = tf.keras.layers.Dense(15, activation='tanh', kernel_initializer=kernel_initializer)\n",
    "        self.dense3 = tf.keras.layers.Dense(10, activation='tanh', kernel_initializer=kernel_initializer)\n",
    "        self.output_layer = tf.keras.layers.Dense(n_actions, activation='linear', kernel_initializer=kernel_initializer)\n",
    "\n",
    "    def call(self, state):\n",
    "        \n",
    "        x = self.dense1(state)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d94bad-03e4-4682-8347-9bb7c18ea645",
   "metadata": {},
   "source": [
    "Initialize the camera agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba5022-490d-43da-adb4-df5f762b841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = CameraAgent(env=env,\n",
    "                 target_q_network=QNetwork(env.n_actions, kernel_initializer),\n",
    "                 selected_q_network=QNetwork(env.n_actions, kernel_initializer),\n",
    "                 memory_size=memory_size,\n",
    "                 batch_size=batch_size,\n",
    "                 n_epochs=n_epochs,\n",
    "                 learning_rate=initial_learning_rate,\n",
    "                 optimizer='RMSprop',\n",
    "                 discount_factor=discount_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df3c986-3280-4bed-b6d7-bc75313b5dd9",
   "metadata": {},
   "source": [
    "Define the cosine learning rate decay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4d90c-6972-4069-ba08-a610eac780a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decayed_learning_rate(step, initial_learning_rate, alpha, n_epochs, decay_steps):\n",
    "    \n",
    "    step = np.min([step, decay_steps])\n",
    "    cosine_decay = 0.5 * (1 + np.cos(np.pi * step / decay_steps))\n",
    "    decayed = (1 - alpha) * cosine_decay + alpha\n",
    "    \n",
    "    return initial_learning_rate * decayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d2258-fa31-466c-a123-312886f30d1b",
   "metadata": {},
   "source": [
    "We are going to use the reward based on divergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82d9ac-d6f4-4aed-a531-725652bfdc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = Rewards(verbose=False)\n",
    "reward_function = rewards.divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabc8ad-9094-4cce-b7ec-fe2e4567d721",
   "metadata": {},
   "source": [
    "Define a transformation function for the reward which is appropriate to detecting vortex structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b3bcd-b625-49b0-8571-f0ed93a96b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_transformation(div):  \n",
    "    return np.max(np.abs(div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba1bc9-7205-4c14-a0e5-531df1a5b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_camera_trajectories_H = np.zeros((n_iterations, n_episodes))\n",
    "saved_camera_trajectories_W = np.zeros((n_iterations, n_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6ee3d-0b25-46ab-8e6e-0941297c2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tic = time.perf_counter()\n",
    "\n",
    "print('- '*50)\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "iter_count = 0\n",
    "total_rewards = []\n",
    "\n",
    "for episode in range(0,n_episodes):\n",
    "\n",
    "    camera_position, cues = ca.env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    # Before we start training the Q-network, only exploration is allowed:\n",
    "    if len(ca.memory.buffer) >= batch_size:\n",
    "        # Exploration probability decreases with training time:\n",
    "        epsilon = epsilon_exp_decay(epsilon_start, iter_count, n=1000)\n",
    "        iter_count += 1\n",
    "    else:\n",
    "        epsilon = 1.0\n",
    "    \n",
    "    if (episode+1) % 10 == 0: print(f'Epsilon: {epsilon:0.3f}')\n",
    "    \n",
    "    for i in range(0,n_iterations):\n",
    "\n",
    "        action = ca.choose_action(cues,\n",
    "                                  epsilon=epsilon)\n",
    "\n",
    "        next_camera_position, next_cues, reward = ca.env.step(action,\n",
    "                                                              reward_function=reward_function,\n",
    "                                                              reward_transformation=reward_transformation,\n",
    "                                                              verbose=False)\n",
    "\n",
    "        ca.remember(cues,\n",
    "                    action,\n",
    "                    reward,\n",
    "                    next_cues)\n",
    "\n",
    "        cues = next_cues\n",
    "        total_reward += reward\n",
    "\n",
    "        saved_camera_trajectories_H[i, episode] = next_camera_position[0]\n",
    "        saved_camera_trajectories_W[i, episode] = next_camera_position[1]\n",
    "\n",
    "    # Train the Q-network, (but hold off with training until batch_size of samples is collected):\n",
    "    if len(ca.memory.buffer) >= batch_size:\n",
    "    \n",
    "        # current_lr = decayed_learning_rate(iter_count, initial_learning_rate, alpha_lr, n_epochs, n_decay_steps)\n",
    "        ca.train(initial_learning_rate)\n",
    "    \n",
    "        if (episode+1) % 1 == 0 :\n",
    "            ca.update_target_network()\n",
    "\n",
    "    else:\n",
    "        print('Not training the Q-network yet...')\n",
    "\n",
    "    if (episode+1) % 10 == 0:\n",
    "        toc = time.perf_counter()\n",
    "        print(f\"Episode: {episode + 1}, Total Reward: {total_reward:0.5f}\")\n",
    "        print(f'\\tThese episodes took: {(toc - tic):0.1f} sec.')\n",
    "        tic = time.perf_counter()\n",
    "\n",
    "    total_rewards.append(total_reward)\n",
    "\n",
    "total_toc = time.perf_counter()\n",
    "print(f'\\n\\nTotal time: {(total_toc - total_tic)/60/60:0.2f} h.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2be5a1-4c63-499a-917f-83ac580c4503",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_losses_collected = np.array(ca.MSE_losses).ravel()\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.semilogy(MSE_losses_collected)\n",
    "plt.xlabel('Epoch #', fontsize=20)\n",
    "plt.ylabel('MSE loss', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3ede3-6efc-47a2-8cff-0f8969ed4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(total_rewards, 'ko--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac9e2c-b815-4516-b0d0-6dc4e12aa4ff",
   "metadata": {},
   "source": [
    "Visualize trajectories taken by the agent in each episode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc71262-f2cd-4469-867e-45fc93cbdf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = -1\n",
    "plt.plot(saved_camera_trajectories_W[:,episode], saved_camera_trajectories_H[:,episode])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade1e32-5894-452f-8031-ee6383908c16",
   "metadata": {},
   "source": [
    "### Visualize the learned policy in the training environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee06b916-96b0-4533-81d8-2fc0bb3f4171",
   "metadata": {},
   "source": [
    "Create sparse samples of camera position on a uniform grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963c04c-4011-46af-8556-5c10b231448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, _, H, W) = ca.env.flowfield.velocity_field_magnitude.shape\n",
    "(H_adm, W_adm) = ca.env.admissible_observation_space\n",
    "idx_H = [i for i in range(0, H_adm) if i % 4 == 0]\n",
    "idx_W = [i for i in range(0, W_adm) if i % 4 == 0]\n",
    "print(len(idx_H) * len(idx_W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4e4e1-0566-4982-8805-9ff2b46f03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_policy = np.ones((H,W)) * np.NaN\n",
    "\n",
    "for h in idx_H:\n",
    "    for w in idx_W:\n",
    "\n",
    "        camera_position = np.array([h, w])\n",
    "        _, cues = ca.env.reset(imposed_camera_position=camera_position)\n",
    "        q_values = ca.target_q_network.predict(cues, verbose=0)\n",
    "        action = np.argmax(q_values)\n",
    "        learned_policy[h, w] = action\n",
    "\n",
    "learned_policy = learned_policy[~np.isnan(learned_policy)]\n",
    "learned_policy = learned_policy.reshape(len(idx_H), len(idx_W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6181d7-86ea-4b77-b644-d32deb4fb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cluster_colors = cmc.batlow(np.linspace(0, 1, 5))\n",
    "cmap = ListedColormap(cluster_colors)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(learned_policy, origin='lower', cmap=cmap, vmin=0, vmax=4)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_ticks([4/5*(i+0.5) for i in range(0,5)])\n",
    "cbar.set_ticklabels(list(ca.env.action_to_verbose_direction.values()))\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20512c1-63f3-4ad6-aa11-875d12a6378d",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Test the trained agent on a new environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a75d3b-73a5-42ad-9832-834733294db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_spec = ParticleSpecs(diameters=(1, 1),\n",
    "                              distances=(2, 2),\n",
    "                              densities=(0.4, 0.4),\n",
    "                              diameter_std=0,\n",
    "                              seeding_mode='random')\n",
    "\n",
    "print(particle_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d234118-b279-4c62-b4d6-b32a737a5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowfield_spec = FlowFieldSpecs(size=(200, 600),\n",
    "                                flowfield_type='random smooth',\n",
    "                                gaussian_filters=(10, 10),\n",
    "                                n_gaussian_filter_iter=10,\n",
    "                                displacement=(2, 2))\n",
    "\n",
    "print(flowfield_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6497f-a5c5-49ef-9f6b-0e3a3bb1d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_spec = MotionSpecs(n_steps=10,\n",
    "                          time_separation=1,\n",
    "                          particle_loss=(0, 0),\n",
    "                          particle_gain=(0, 0))\n",
    "\n",
    "print(motion_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd73503-1433-4b54-8759-37de5bd4448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_spec = ImageSpecs(exposures=(0.98, 0.98),\n",
    "                        maximum_intensity=2**16-1,\n",
    "                        laser_beam_thickness=1,\n",
    "                        laser_over_exposure=1,\n",
    "                        laser_beam_shape=0.95,\n",
    "                        alpha=1/8,\n",
    "                        clip_intensities=True,\n",
    "                        normalize_intensities=False)\n",
    "\n",
    "print(image_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce179c7-e064-41c7-9afe-a49072c74f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = PIVEnv(interrogation_window_size=interrogation_window_size,\n",
    "                  interrogation_window_size_buffer=10,\n",
    "                  cues_function=cues_function,\n",
    "                  particle_spec=particle_spec,\n",
    "                  motion_spec=motion_spec,\n",
    "                  image_spec=image_spec,\n",
    "                  flowfield_spec=flowfield_spec,\n",
    "                  user_flowfield=None,\n",
    "                  inference_model=None,\n",
    "                  random_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f62eb0-c782-4351-bad7-1975b346983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_position, cues = test_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c47dc-f81b-400c-84be-45e5a32b1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = test_env.render(camera_position,\n",
    "                     c='white',\n",
    "                     s=20,\n",
    "                     lw=1,\n",
    "                     normalize_cbars=True,\n",
    "                     cmap=cmc.roma,\n",
    "                     add_streamplot=True,\n",
    "                     streamplot_density=3,\n",
    "                     streamplot_color='k',\n",
    "                     streamplot_linewidth=0.3,\n",
    "                     figsize=(15,6), \n",
    "                     filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f607fe8-e897-4571-896d-120816194368",
   "metadata": {},
   "source": [
    "### Visualize the learned policy in the test environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161789e8-3056-4f60-b525-3b69af0461a9",
   "metadata": {},
   "source": [
    "Create sparse samples of camera position on a uniform grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495cdc5-376d-4c91-849f-a959c1dcd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, _, H, W) = test_env.flowfield.velocity_field_magnitude.shape\n",
    "(H_adm, W_adm) = test_env.admissible_observation_space\n",
    "idx_H = [i for i in range(0, H_adm) if i % 10 == 0]\n",
    "idx_W = [i for i in range(0, W_adm) if i % 10 == 0]\n",
    "print(len(idx_H) * len(idx_W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be2f5d-91c8-4128-ba63-a7e7a0c5e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_policy = np.ones((H,W)) * np.NaN\n",
    "\n",
    "for h in idx_H:\n",
    "    for w in idx_W:\n",
    "\n",
    "        camera_position = np.array([h, w])\n",
    "        _, cues = test_env.reset(imposed_camera_position=camera_position)\n",
    "        q_values = ca.target_q_network.predict(cues, verbose=0)\n",
    "        action = np.argmax(q_values)\n",
    "        learned_policy[h, w] = action\n",
    "\n",
    "learned_policy = learned_policy[~np.isnan(learned_policy)]\n",
    "learned_policy = learned_policy.reshape(len(idx_H), len(idx_W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746752f7-ada1-49c4-b569-a1046e8fab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cluster_colors = cmc.batlow(np.linspace(0, 1, 5))\n",
    "cmap = ListedColormap(cluster_colors)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(learned_policy, origin='lower', cmap=cmap, vmin=0, vmax=4)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_ticks([4/5*(i+0.5) for i in range(0,5)])\n",
    "cbar.set_ticklabels(list(test_env.action_to_verbose_direction.values()))\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61effbaa-ce78-416e-985f-7056c060931e",
   "metadata": {},
   "source": [
    "### Visualize one sample trajectory in the test environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148de47-151e-46de-9443-80bdec7c38f5",
   "metadata": {},
   "source": [
    "We are going to take a number of steps in the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bced6-313b-4529-acef-912e521faab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8ac95-8140-4667-a630-726fa6a517c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_camera_trajectories = np.zeros((n_steps,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32dd6d9-6038-4243-b06c-ed9990ac525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_position, cues = test_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a71b47-6d25-4223-8ce2-5e78bbe44965",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,n_steps):\n",
    "\n",
    "    saved_camera_trajectories[i, 0] = camera_position[0]\n",
    "    saved_camera_trajectories[i, 1] = camera_position[1]\n",
    "\n",
    "    q_values = ca.target_q_network.predict(cues, verbose=0)\n",
    "\n",
    "    action = np.argmax(q_values)\n",
    "\n",
    "    if i%10 == 0: print(test_env.action_to_verbose_direction[action])\n",
    "\n",
    "    camera_position, cues, reward = test_env.step(action=action,\n",
    "                                                  reward_function=reward_function,\n",
    "                                                  reward_transformation=reward_transformation,\n",
    "                                                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e239c85-2f49-4a0a-8b2a-193ba1ddf9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(test_env.flowfield.velocity_field,\n",
    "                saved_camera_trajectories,\n",
    "                interrogation_window_size=interrogation_window_size,\n",
    "                c_path='white',\n",
    "                c_init='white',\n",
    "                c_final='black',\n",
    "                s=20,\n",
    "                lw=2,\n",
    "                xlabel=None,\n",
    "                ylabel=None,\n",
    "                xticks=True,\n",
    "                yticks=True,\n",
    "                cmap=cmc.roma,\n",
    "                add_streamplot=True,\n",
    "                streamplot_density=4,\n",
    "                streamplot_color='k',\n",
    "                streamplot_linewidth=0.4,\n",
    "                figsize=(15,5),\n",
    "                dpi=300,\n",
    "                filename=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f71e0a-c9cd-48cf-8fb9-c19ffd4b1faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a203c-cb78-4ab3-9daf-5a9a0552db14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19ba14-fd61-4de3-acb3-ff268c3e32f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65000f7-2bd9-4976-b4b3-4536413c96d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c978e6-6d86-43e0-8be4-c337b8cd7203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d80d73-048e-458a-8bdb-58de93014d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311d2f1-5334-402c-a1c1-e4d4f7dc50e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eedad2d-2156-421d-86fa-09d3bd5c18d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc1ffd-6ff3-4181-a5ad-088d949b13bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfe003-08bf-4b8b-853b-32035713da01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91af301-1b6e-4d96-947c-c37187b7c7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aaff77-d256-42cc-93c1-147e79e21327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d509ef20-ce15-47ce-8f42-6c2d67c192e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4097346-0364-4f5a-9815-a17b7b33d7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e8f6565-17de-451a-84ab-a4857f44cb4e",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
