{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603d26ae-d712-41bf-9990-92c4248bf185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lvpyio module is not available on macOS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamilazdybal/anaconda3/envs/lima-pykitPIV/lib/python3.10/site-packages/lima/__init__.py:14: UserWarning: GPU not available and could not be checked!\n",
      "  warn(\"GPU not available and could not be checked!\")\n",
      "2025-05-22 13:16:38.159172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms\n",
    "from rich import print\n",
    "from torch.utils.data import DataLoader\n",
    "import lima\n",
    "import glob\n",
    "import h5py\n",
    "import skimage.io as io\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cmcrameri.cm as cmc\n",
    "from pykitPIV import Particle, FlowField, Motion, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a31101b-7bc1-4dce-a4cc-dbcef49d30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images = False\n",
    "filename = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579f51f3-aa49-42c4-a40c-c76383a385fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9529ac-04f7-45a7-b392-8bc7b6379c8a",
   "metadata": {},
   "source": [
    "<a id=train-LIMA></a>\n",
    "***\n",
    "\n",
    "## Train `LIMA` with the generated images\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7e34e-b9d5-4801-bdb1-8edd07ccd4c3",
   "metadata": {},
   "source": [
    "<a id=train-LIMA-input-data></a>\n",
    "### Prepare input dataset for LIMA\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7b01577-ff6f-4dc7-8fde-fc9f02cbea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([lima.datatransform.RandomAffine(degrees=17, translate=(0.2, 0.2), scale=(0.9, 2.0)),\n",
    "                                            lima.datatransform.RandomHorizontalFlip(),\n",
    "                                            lima.datatransform.RandomVerticalFlip(),\n",
    "                                            lima.datatransform.ToTensor(),\n",
    "                                            lima.datatransform.RandomBrightness(factor=(0.5, 2)),\n",
    "                                            lima.datatransform.RandomNoise(std=(0, 0)),])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb78a4-858c-4864-b76f-18dd4af76a89",
   "metadata": {},
   "source": [
    "#### Use dataset generated with `pykitPIV`:\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e705b1-cc07-44e1-8ea0-27e9d4d046db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class pykitPIVDataset(Dataset):\n",
    "#     \"\"\"Load pykitPIV-generated dataset\"\"\"\n",
    "\n",
    "#     def __init__(self, image_pairs, targets, transform=None, n_samples=None, pin_to_ram=False):\n",
    "\n",
    "#         self.data = image_pairs.astype(np.float32)\n",
    "#         self.target = targets.astype(np.float32)\n",
    "\n",
    "#         if n_samples:\n",
    "#             self.data = self.data[:n_samples]\n",
    "#             self.target = self.target[:n_samples]\n",
    "#         if pin_to_ram:\n",
    "#             self.data = np.array(self.data)\n",
    "#             self.target = np.array(self.target)\n",
    "\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "#         sample = self.data[idx], self.target[idx]\n",
    "#         if self.transform:\n",
    "#             sample = self.transform(sample)\n",
    "\n",
    "#         return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e9992-d893-465a-9771-5d7731d75c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = pykitPIVDataset(image_pairs=image_pairs_train,\n",
    "#                                 targets=targets_train,\n",
    "#                                 transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f81ad-1d42-441d-96e1-15eb95471a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = pykitPIVDataset(image_pairs=image_pairs_test,\n",
    "#                                 targets=targets_test,\n",
    "#                                 transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df0096-f682-4e71-862d-99b77790e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pykitPIVDatasetFromPath(Dataset):\n",
    "    \"\"\"Load pykitPIV-generated dataset\"\"\"\n",
    "\n",
    "    def __init__(self, path, transform=None, n_samples=None, pin_to_ram=False):\n",
    "        \n",
    "        f = h5py.File(path, \"r\")\n",
    "        self.data = f[\"I\"]\n",
    "        self.target = np.array(f[\"targets\"])\n",
    "\n",
    "        print(self.target.max())\n",
    "\n",
    "        if n_samples:\n",
    "            self.data = self.data[:n_samples]\n",
    "            self.target = self.target[:n_samples]\n",
    "            \n",
    "        if pin_to_ram:\n",
    "            self.data = np.array(self.data)\n",
    "            self.target = np.array(self.target)\n",
    "            f.close()\n",
    "            \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        sample = self.data[idx], self.target[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c456ab-4b17-4ba8-8bb3-6347a523da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pykitPIVDatasetFromPath(path='PIV-dataset-train.h5',\n",
    "                                        transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9cb3cb-bc1d-4c57-8a4c-23c4e14e3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d86dd3-562b-43b9-9e4a-257ad8c7d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pykitPIVDatasetFromPath(path='PIV-dataset-test.h5',\n",
    "                                       transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c38dcc-9ca2-4e76-b7b3-031e9bfb180d",
   "metadata": {},
   "source": [
    "#### Use dataset generated with Matlab:\n",
    "\n",
    "[Go to the top](#top-page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5074828-00b9-455c-bced-0efbb430f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'PIV_n3_s180_maxd10_rnd_v1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc9631-f90f-4ff5-b82f-8305e7be51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = h5py.File(path, \"r\")\n",
    "\n",
    "# images = f[\"I\"]\n",
    "# images = np.array(images)\n",
    "# targets = f[\"target\"]\n",
    "# targets = np.array(targets)[:,2:4,:,:]\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce131801-974f-404e-a402-52aebd83a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.array(images)[0,0,:,:], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68a329-5720-49b1-8a89-e1f7793e0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HDF5Dataset(Dataset):\n",
    "#     \"\"\"HDF5Dataset loaded\"\"\"\n",
    "\n",
    "#     def __init__(self, path, transform=None, n_samples=None, pin_to_ram=False):\n",
    "#         f = h5py.File(path, \"r\")\n",
    "#         self.data = f[\"I\"]\n",
    "#         self.target = np.array(f[\"target\"])[:,2:4,:,:]\n",
    "\n",
    "#         if n_samples:\n",
    "#             self.data = self.data[:n_samples]\n",
    "#             self.target = self.target[:n_samples]\n",
    "#         if pin_to_ram:\n",
    "#             self.data = np.array(self.data)\n",
    "#             self.target = np.array(self.target)\n",
    "#             f.close()\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "#         sample = self.data[idx], self.target[idx]\n",
    "#         if self.transform:\n",
    "#             sample = self.transform(sample)\n",
    "\n",
    "#         return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd2f0d-3ebc-4cd9-ae9a-276a418056d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = HDF5Dataset(path=path,\n",
    "#                             transform=transform,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35612cb1-32d0-4fbe-a59b-e292b8ad365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = HDF5Dataset(path=path,\n",
    "#                            transform=transform,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb3fb9-edee-4317-804a-a81600b35a0e",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "© K. Zdybał, C. Mucignat, S. Kunz, I. Lunati (2025)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
